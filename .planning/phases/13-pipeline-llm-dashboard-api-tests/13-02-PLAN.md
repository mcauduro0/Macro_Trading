---
phase: 13-pipeline-llm-dashboard-api-tests
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/narrative/__init__.py
  - src/narrative/generator.py
  - src/narrative/templates.py
  - src/core/config.py
  - .env.example
  - tests/test_narrative/__init__.py
  - tests/test_narrative/test_generator.py
autonomous: true
requirements: [LLM-01, LLM-02, LLM-03, LLM-04]
user_setup:
  - service: anthropic
    why: "LLM narrative generation via Claude API"
    env_vars:
      - name: ANTHROPIC_API_KEY
        source: "Anthropic Console -> API Keys -> Create Key (https://console.anthropic.com/)"
    dashboard_config: []

must_haves:
  truths:
    - "NarrativeGenerator.generate() produces 800-1500 word macro brief when ANTHROPIC_API_KEY is set"
    - "NarrativeGenerator.generate() falls back to structured template when ANTHROPIC_API_KEY is empty"
    - "Template fallback produces clean signal tables with directions and confidences (no prose)"
    - "Narrative covers regime, inflation, monetary policy, fiscal, FX, portfolio positioning, and key risks"
    - "ANTHROPIC_API_KEY is in .env.example and Settings class"
  artifacts:
    - path: "src/narrative/generator.py"
      provides: "NarrativeGenerator class with Claude API and template fallback"
      contains: "class NarrativeGenerator"
    - path: "src/narrative/templates.py"
      provides: "Template-based fallback narrative generator"
      contains: "def render_template"
    - path: "src/core/config.py"
      provides: "ANTHROPIC_API_KEY in Settings"
      contains: "anthropic_api_key"
    - path: "tests/test_narrative/test_generator.py"
      provides: "Unit tests for both LLM and template paths"
      min_lines: 80
  key_links:
    - from: "src/narrative/generator.py"
      to: "anthropic"
      via: "Anthropic Python SDK client.messages.create()"
      pattern: "anthropic.Anthropic"
    - from: "src/narrative/generator.py"
      to: "src/narrative/templates.py"
      via: "Fallback when API key is empty"
      pattern: "render_template"
    - from: "src/narrative/generator.py"
      to: "src/agents/base.py"
      via: "Consumes AgentReport and AgentSignal for prompt construction"
      pattern: "AgentReport"
---

<objective>
Build the NarrativeGenerator that produces a daily macro brief using Claude API (Anthropic SDK) with a structured template fallback when the API key is unavailable.

Purpose: The daily macro brief transforms raw quantitative signals into an actionable morning call note that portfolio managers and quants can quickly digest. The template fallback ensures the pipeline never fails due to missing LLM access.

Output: src/narrative/ package with NarrativeGenerator class, template fallback module, Settings update for ANTHROPIC_API_KEY, .env.example update, unit tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-pipeline-llm-dashboard-api-tests/13-CONTEXT.md
@src/agents/base.py
@src/agents/registry.py
@src/core/config.py
@.env.example
</context>

<tasks>

<task type="auto">
  <name>Task 1: NarrativeGenerator with Claude API integration and template fallback</name>
  <files>
    src/narrative/__init__.py
    src/narrative/generator.py
    src/narrative/templates.py
    src/core/config.py
    .env.example
  </files>
  <action>
**Settings update (`src/core/config.py`):**
Add `anthropic_api_key: str = ""` to the Settings class, in the "API Keys" section alongside `fred_api_key`.

**.env.example update:**
Add `ANTHROPIC_API_KEY=` in the "External API Keys" section, after `FRED_API_KEY=`.

**NarrativeGenerator class (`src/narrative/generator.py`):**

1. `__init__(self, api_key: str | None = None)` — If api_key is None, reads from `settings.anthropic_api_key`. Stores `self._has_api_key = bool(api_key)`. If key available, creates `self._client = anthropic.Anthropic(api_key=api_key)`. Import anthropic conditionally (try/except ImportError with helpful message).

2. `generate(self, agent_reports: dict[str, AgentReport], features: dict | None = None, as_of_date: date | None = None) -> NarrativeBrief` — Main entry point.
   - If `self._has_api_key`: calls `_generate_llm(agent_reports, features, as_of_date)`
   - Else: calls `_generate_template(agent_reports, features, as_of_date)`
   - Returns `NarrativeBrief` dataclass.

3. `_generate_llm(self, ...) -> NarrativeBrief` — Builds structured prompt from agent signals, calls Claude API:
   - Model: `claude-sonnet-4-5` (fast, cost-effective for daily generation)
   - System prompt: "You are a senior macro strategist at a global macro hedge fund. Write an internal morning call note for the trading desk."
   - User prompt: structured data dump of all agent signals (direction, strength, confidence, key metrics) plus any features dict data, followed by instructions:
     - "Write a daily macro brief (800-1500 words) covering: Executive Summary (2-3 sentences), Regime Assessment, Inflation Dynamics, Monetary Policy, Fiscal Outlook, FX & External, Portfolio Positioning, Key Risks & Watchlist."
     - "Tone: internal trading desk — direct, first-person plural. 'We're seeing hawkish signals.' 'Our regime model flipped to risk-off.'"
   - max_tokens: 2048
   - Wrap API call in try/except; on any error, fall back to template and set `NarrativeBrief.source = "template_fallback"`.

4. `_generate_template(self, ...) -> NarrativeBrief` — Delegates to `templates.render_template()`.

5. `_build_prompt_data(self, agent_reports, features) -> str` — Serializes agent reports into structured text for the LLM prompt. For each agent: agent_id, signal_count, then for each signal: signal_id, direction, strength, confidence, value. Include features dict if provided.

**NarrativeBrief dataclass:**
- `content: str` — The narrative text
- `source: str` — "llm" or "template" or "template_fallback"
- `model: str | None` — Claude model used (None for template)
- `as_of_date: date`
- `generated_at: datetime`
- `word_count: int`

**Template fallback (`src/narrative/templates.py`):**

`render_template(agent_reports: dict[str, AgentReport], features: dict | None, as_of_date: date) -> str`

Per CONTEXT.md decision: structured data dump with tables, no prose. Output format:

```
DAILY MACRO BRIEF — 2024-01-15
Source: Template (no LLM API key configured)
═══════════════════════════════════════════

AGENT SIGNALS
┌─────────────────────┬───────────┬──────────┬────────────┐
│ Signal              │ Direction │ Strength │ Confidence │
├─────────────────────┼───────────┼──────────┼────────────┤
│ INFLATION_BR_...    │ LONG      │ STRONG   │ 0.85       │
│ ...                 │ ...       │ ...      │ ...        │
└─────────────────────┴───────────┴──────────┴────────────┘

CONSENSUS BY ASSET CLASS
┌──────────────┬───────────┬────────────┐
│ Asset Class  │ Direction │ Confidence │
├──────────────┼───────────┼────────────┤
│ FIXED_INCOME │ SHORT     │ 0.72       │
│ ...          │ ...       │ ...        │
└──────────────┴───────────┴────────────┘

Generated: 2024-01-15T08:00:00Z
```

Use plain ASCII box-drawing characters. Group signals by agent. Include all available data points. Fast and scannable per CONTEXT.md.

**Package init (`src/narrative/__init__.py`):**
Export: NarrativeGenerator, NarrativeBrief, render_template.
  </action>
  <verify>
python -c "from src.narrative import NarrativeGenerator, NarrativeBrief; print('Narrative imports OK')"
python -c "from src.core.config import settings; assert hasattr(settings, 'anthropic_api_key'); print('Config OK')"
grep -q 'ANTHROPIC_API_KEY' .env.example && echo '.env.example OK'
  </verify>
  <done>
NarrativeGenerator class with Claude API integration and template fallback exists, ANTHROPIC_API_KEY in Settings and .env.example, NarrativeBrief dataclass, template produces structured signal tables without prose.
  </done>
</task>

<task type="auto">
  <name>Task 2: Narrative unit tests for both LLM and template paths</name>
  <files>
    tests/test_narrative/__init__.py
    tests/test_narrative/test_generator.py
  </files>
  <action>
**Unit tests (`tests/test_narrative/test_generator.py`):**

Create comprehensive tests using `unittest.mock.patch` to mock the Anthropic SDK. Tests should NOT require a real API key or API access.

1. `test_narrative_brief_dataclass` — NarrativeBrief fields, word_count computation.
2. `test_generate_with_api_key_calls_llm` — Mock anthropic.Anthropic; verify client.messages.create() is called with correct model and system prompt.
3. `test_generate_without_api_key_uses_template` — NarrativeGenerator(api_key="") falls back to template, source="template".
4. `test_llm_fallback_on_api_error` — Mock API to raise anthropic.APIError; verify graceful fallback to template with source="template_fallback".
5. `test_template_output_contains_signal_table` — Template output contains signal direction, strength, confidence in tabular format.
6. `test_template_output_no_prose` — Template output does not contain filler words like "suggests", "indicates", "appears". Only data tables.
7. `test_template_groups_by_agent` — Each agent section appears with its signals grouped together.
8. `test_build_prompt_data_serialization` — _build_prompt_data() includes all agent signals with direction/strength/confidence.
9. `test_narrative_word_count_range` — LLM mock returns 1000-word text; verify NarrativeBrief.word_count is in expected range.
10. `test_settings_has_anthropic_key` — Import settings, verify anthropic_api_key attribute exists.

Build mock AgentReport and AgentSignal objects for test fixtures using the dataclasses from `src/agents/base`. Create a helper `_make_mock_reports()` that returns a dict of 5 agent reports with realistic signal data (3-5 signals each with varied directions and confidences).
  </action>
  <verify>
pytest tests/test_narrative/ -v  # all tests pass
  </verify>
  <done>
10+ narrative tests pass covering LLM path (mocked), template fallback, error handling, output format validation, and config integration. No real API calls made.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.narrative import NarrativeGenerator, NarrativeBrief"` succeeds
2. `grep -q 'anthropic_api_key' src/core/config.py` confirms config field
3. `grep -q 'ANTHROPIC_API_KEY' .env.example` confirms env var
4. `pytest tests/test_narrative/ -v` — all tests pass
5. Template output is pure tables, no prose filler
</verification>

<success_criteria>
- NarrativeGenerator uses Claude API (Anthropic SDK) when ANTHROPIC_API_KEY is set
- Daily macro brief covers regime, inflation, monetary policy, fiscal, FX, portfolio, risks
- Tone is internal trading desk, first-person plural, 800-1500 words target
- Template fallback produces structured data tables (no prose) when API key is empty
- Graceful fallback to template on any API error
- ANTHROPIC_API_KEY in .env.example and Settings class
- All narrative tests pass without real API access
</success_criteria>

<output>
After completion, create `.planning/phases/13-pipeline-llm-dashboard-api-tests/13-02-SUMMARY.md`
</output>
