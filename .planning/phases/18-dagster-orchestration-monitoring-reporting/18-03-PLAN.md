---
phase: 18-dagster-orchestration-monitoring-reporting
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - docker-compose.yml
  - monitoring/grafana/provisioning/datasources/timescaledb.yml
  - monitoring/grafana/provisioning/dashboards/dashboards.yml
  - monitoring/grafana/dashboards/pipeline_health.json
  - monitoring/grafana/dashboards/signal_overview.json
  - monitoring/grafana/dashboards/risk_dashboard.json
  - monitoring/grafana/dashboards/portfolio_performance.json
autonomous: true
requirements:
  - MNTR-01
  - MNTR-02

must_haves:
  truths:
    - "Grafana runs at port 3002 and loads automatically with TimescaleDB datasource pre-configured"
    - "Pipeline health dashboard shows connector status grid (green/yellow/red) and timeline of pipeline runs with duration bars"
    - "Signal overview dashboard shows heatmap matrix with asset classes as rows and strategies as columns"
    - "Risk dashboard shows VaR as gauge dials with limit thresholds and stress scenario bar chart"
    - "Portfolio performance dashboard shows equity curve and attribution breakdown"
    - "All 4 dashboards auto-refresh every 15 minutes per user decision"
  artifacts:
    - path: "docker-compose.yml"
      provides: "Grafana service on port 3002"
      contains: "grafana"
    - path: "monitoring/grafana/provisioning/datasources/timescaledb.yml"
      provides: "TimescaleDB datasource auto-provisioning"
      contains: "postgresql"
    - path: "monitoring/grafana/provisioning/dashboards/dashboards.yml"
      provides: "Dashboard provisioning config pointing to JSON files"
      contains: "dashboards"
    - path: "monitoring/grafana/dashboards/pipeline_health.json"
      provides: "Pipeline health Grafana dashboard"
      min_lines: 50
    - path: "monitoring/grafana/dashboards/signal_overview.json"
      provides: "Signal overview Grafana dashboard"
      min_lines: 50
    - path: "monitoring/grafana/dashboards/risk_dashboard.json"
      provides: "Risk monitoring Grafana dashboard"
      min_lines: 50
    - path: "monitoring/grafana/dashboards/portfolio_performance.json"
      provides: "Portfolio performance Grafana dashboard"
      min_lines: 50
  key_links:
    - from: "docker-compose.yml"
      to: "monitoring/grafana/provisioning/"
      via: "volume mount for auto-provisioning"
      pattern: "monitoring/grafana"
    - from: "monitoring/grafana/provisioning/datasources/timescaledb.yml"
      to: "timescaledb service"
      via: "PostgreSQL connection URL"
      pattern: "timescaledb:5432"
    - from: "monitoring/grafana/provisioning/dashboards/dashboards.yml"
      to: "monitoring/grafana/dashboards/*.json"
      via: "path provisioning"
      pattern: "/var/lib/grafana/dashboards"
---

<objective>
Set up Grafana monitoring with Docker Compose service, automatic TimescaleDB datasource provisioning, and 4 pre-configured dashboards (pipeline health, signal overview, risk, portfolio performance) that load on first start.

Purpose: Make the entire system observable through visual dashboards. Operators can monitor pipeline health, scan signals across the book, track risk limits, and review portfolio performance at a glance -- all without querying the database directly.

Output: Grafana Docker service, datasource config, dashboard provisioning, and 4 dashboard JSON definitions.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@docker-compose.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Grafana Docker Compose service and datasource provisioning, pipeline_health and signal_overview dashboards</name>
  <files>
    docker-compose.yml
    monitoring/grafana/provisioning/datasources/timescaledb.yml
    monitoring/grafana/provisioning/dashboards/dashboards.yml
    monitoring/grafana/dashboards/pipeline_health.json
    monitoring/grafana/dashboards/signal_overview.json
  </files>
  <action>
**docker-compose.yml**: Add Grafana service after the existing services (before volumes section):

```yaml
  grafana:
    image: grafana/grafana-oss:11.4.0
    container_name: macro_grafana
    ports:
      - "3002:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: macro_grafana
      GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /var/lib/grafana/dashboards/pipeline_health.json
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      timescaledb:
        condition: service_healthy
    profiles:
      - monitoring
    restart: unless-stopped
```

Add `grafana_data:` to the volumes section at the bottom.

Use the `monitoring` profile so Grafana does not start with default `docker compose up`.

**monitoring/grafana/provisioning/datasources/timescaledb.yml**: Create datasource provisioning:

```yaml
apiVersion: 1
datasources:
  - name: TimescaleDB
    type: postgres
    access: proxy
    url: timescaledb:5432
    database: macro_trading
    user: macro_user
    secureJsonData:
      password: macro_pass
    jsonData:
      sslmode: disable
      maxOpenConns: 5
      maxIdleConns: 2
      connMaxLifetime: 14400
      postgresVersion: 1600
      timescaledb: true
    isDefault: true
    editable: false
```

**monitoring/grafana/provisioning/dashboards/dashboards.yml**: Create dashboard provisioning config:

```yaml
apiVersion: 1
providers:
  - name: 'macro-trading'
    orgId: 1
    folder: 'Macro Trading'
    type: file
    disableDeletion: false
    editable: true
    options:
      path: /var/lib/grafana/dashboards
      foldersFromFilesStructure: false
```

**monitoring/grafana/dashboards/pipeline_health.json**: Create pipeline health dashboard JSON. This is a standard Grafana dashboard JSON with:

Dashboard structure (per user decision: connector status grid at top + timeline below):
- **Title**: "Pipeline Health"
- **Refresh**: "15m" (auto-refresh every 15 minutes per user decision)
- **uid**: "pipeline-health"
- **Row 1 - Connector Status Grid**: 6 stat panels in a 3x2 grid, one per connector (bcb_sgs, fred, yahoo, bcb_ptax, b3_market_data, treasury_gov). Each panel queries `pipeline_runs` table for the latest run status per connector:
  ```sql
  SELECT status, duration_seconds, started_at
  FROM pipeline_runs
  WHERE step_name = '${connector_name}'
  ORDER BY started_at DESC LIMIT 1
  ```
  Use value mappings: "SUCCESS" -> green, "FAILED" -> red, "RUNNING" -> yellow. Panel type: `stat`.

- **Row 2 - Pipeline Timeline**: A timeseries panel showing pipeline run durations over time:
  ```sql
  SELECT started_at AS time, duration_seconds AS "Duration (s)", status
  FROM pipeline_runs
  WHERE $__timeFilter(started_at)
  ORDER BY started_at
  ```
  Panel type: `timeseries` with bars rendering mode and color by status field.

- **Row 3 - Error Log**: A table panel showing recent pipeline errors:
  ```sql
  SELECT started_at AS "Time", step_name AS "Step", error_message AS "Error"
  FROM pipeline_runs
  WHERE status = 'FAILED' AND $__timeFilter(started_at)
  ORDER BY started_at DESC LIMIT 20
  ```

Use standard Grafana dashboard JSON format with `__inputs`, `__elements`, `__requires`, panels array, templating section, time range (default last 24h), and the TimescaleDB datasource UID set to "${DS_TIMESCALEDB}" with variable.

**monitoring/grafana/dashboards/signal_overview.json**: Create signal overview dashboard JSON:

Dashboard structure (per user decision: heatmap matrix with asset classes as rows, strategies as columns):
- **Title**: "Signal Overview"
- **Refresh**: "15m"
- **uid**: "signal-overview"
- **Row 1 - Signal Heatmap**: A table panel styled as a heatmap showing the latest signal values. Query:
  ```sql
  SELECT strategy_id, instrument, direction, strength, confidence,
         CASE WHEN direction = 'LONG' THEN confidence ELSE -confidence END AS signal_value,
         generated_at
  FROM strategy_signals
  WHERE generated_at >= NOW() - INTERVAL '24 hours'
  ORDER BY strategy_id
  ```
  Use cell coloring with thresholds: red (-1 to -0.3), yellow (-0.3 to 0.3), green (0.3 to 1.0). Panel type: `table` with color-coded cells. **Important**: To achieve the locked decision's "asset classes as rows, strategies as columns" matrix layout, apply Grafana Transform chain: (1) "Group by" on asset_class field, (2) "Organize fields" to create columns per strategy_id with signal_value as cell values. Alternatively, use a PostgreSQL `crosstab()` query from the tablefunc extension to pivot the result directly in SQL. The final panel must render as a pivoted matrix, not a flat list.

- **Row 2 - Signal Strength Distribution**: A bar gauge panel showing conviction levels by asset class:
  ```sql
  SELECT
    CASE
      WHEN strategy_id LIKE 'FX%' THEN 'FX'
      WHEN strategy_id LIKE 'RATES%' THEN 'Rates'
      WHEN strategy_id LIKE 'INF%' THEN 'Inflation'
      WHEN strategy_id LIKE 'CUPOM%' THEN 'Cupom'
      WHEN strategy_id LIKE 'SOV%' THEN 'Sovereign'
      WHEN strategy_id LIKE 'CROSS%' THEN 'Cross-Asset'
    END AS asset_class,
    AVG(confidence) AS avg_conviction
  FROM strategy_signals
  WHERE generated_at >= NOW() - INTERVAL '24 hours'
  GROUP BY asset_class
  ```

- **Row 3 - Signal Flip Timeline**: A timeseries panel showing signal direction changes over time.
  </action>
  <verify>
1. Run `python -c "import json; d=json.load(open('monitoring/grafana/dashboards/pipeline_health.json')); print(f'Pipeline Health: {len(d.get(\"panels\", []))} panels'); assert d.get('refresh') == '15m'"` — must succeed with panels count.
2. Run `python -c "import json; d=json.load(open('monitoring/grafana/dashboards/signal_overview.json')); print(f'Signal Overview: {len(d.get(\"panels\", []))} panels')"` — must succeed.
3. Run `grep 'grafana' docker-compose.yml` — must find the service.
4. Run `cat monitoring/grafana/provisioning/datasources/timescaledb.yml | head -5` — must show apiVersion.
  </verify>
  <done>
Grafana Docker service on port 3002 with monitoring profile, TimescaleDB datasource auto-provisioned, dashboard provisioner configured, pipeline_health dashboard with connector status grid + timeline + error log, signal_overview dashboard with heatmap + conviction distribution + flip timeline. All dashboards auto-refresh every 15 minutes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Risk dashboard and portfolio performance dashboard JSON definitions</name>
  <files>
    monitoring/grafana/dashboards/risk_dashboard.json
    monitoring/grafana/dashboards/portfolio_performance.json
  </files>
  <action>
**monitoring/grafana/dashboards/risk_dashboard.json**: Create risk monitoring dashboard JSON.

Dashboard structure (per user decision: VaR gauge dials with thresholds + stress scenario bar chart):
- **Title**: "Risk Dashboard"
- **Refresh**: "15m"
- **uid**: "risk-dashboard"

- **Row 1 - VaR Gauges**: 4 gauge panels in a row:
  1. "VaR 95% (1D)" — gauge showing current 1-day VaR at 95% confidence. Query the latest risk computation result. Thresholds: green < 2%, yellow 2-5%, red > 5%. Panel type: `gauge`.
  2. "VaR 99% (1D)" — same for 99% confidence. Thresholds: green < 3%, yellow 3-7%, red > 7%.
  3. "CVaR 95%" — conditional VaR gauge. Similar thresholds shifted higher.
  4. "Max Drawdown" — current drawdown from peak. Thresholds: green < 5%, yellow 5-10%, red > 10%.

  Queries use the risk computation results table or API-populated materialized view. Example:
  ```sql
  SELECT var_95_pct, var_99_pct, cvar_95_pct, max_drawdown
  FROM risk_metrics_daily
  WHERE computed_at = (SELECT MAX(computed_at) FROM risk_metrics_daily)
  ```
  If table does not exist, use placeholder with manual value input for demo.

- **Row 2 - Stress Test Results**: A horizontal bar chart showing P&L impact of each stress scenario:
  ```sql
  SELECT scenario_name, portfolio_pnl_pct
  FROM stress_test_results
  WHERE run_date = (SELECT MAX(run_date) FROM stress_test_results)
  ORDER BY portfolio_pnl_pct ASC
  ```
  Panel type: `barchart` with horizontal orientation. Color negative values red, positive green.

- **Row 3 - Limit Utilization**: A bar gauge panel showing utilization % for key risk limits:
  ```sql
  SELECT limit_name, utilization_pct
  FROM risk_limits_status
  WHERE checked_at = (SELECT MAX(checked_at) FROM risk_limits_status)
  ```
  Thresholds: green < 60%, yellow 60-80%, red > 80%. Panel type: `bargauge`.

- **Row 4 - VaR History**: A timeseries panel showing VaR evolution over time:
  ```sql
  SELECT computed_at AS time, var_95_pct AS "VaR 95%", var_99_pct AS "VaR 99%"
  FROM risk_metrics_daily
  WHERE $__timeFilter(computed_at)
  ORDER BY computed_at
  ```

**monitoring/grafana/dashboards/portfolio_performance.json**: Create portfolio performance dashboard JSON (Claude's discretion: standard equity curve + attribution).

Dashboard structure:
- **Title**: "Portfolio Performance"
- **Refresh**: "15m"
- **uid**: "portfolio-performance"

- **Row 1 - Portfolio Summary Stats**: 4 stat panels:
  1. "Total Return" — cumulative return since inception
  2. "Sharpe Ratio" — rolling 252-day annualized Sharpe
  3. "Current Leverage" — gross leverage ratio
  4. "Active Positions" — count of non-zero positions

- **Row 2 - Equity Curve**: A timeseries panel showing portfolio NAV evolution:
  ```sql
  SELECT timestamp AS time, total_equity AS "Portfolio NAV"
  FROM portfolio_state
  WHERE $__timeFilter(timestamp)
  ORDER BY timestamp
  ```
  Panel type: `timeseries` with line rendering, gradient fill.

- **Row 3 - Strategy Attribution**: A pie chart showing current allocation by strategy:
  ```sql
  SELECT strategy_id, SUM(ABS(weight)) AS allocation
  FROM portfolio_state
  WHERE timestamp = (SELECT MAX(timestamp) FROM portfolio_state)
  GROUP BY strategy_id
  ```
  Panel type: `piechart`.

- **Row 4 - Monthly Returns Heatmap**: A heatmap panel showing returns by month/year:
  ```sql
  SELECT
    date_trunc('month', timestamp) AS time,
    (last(total_equity, timestamp) / first(total_equity, timestamp) - 1) * 100 AS monthly_return
  FROM portfolio_state
  WHERE $__timeFilter(timestamp)
  GROUP BY date_trunc('month', timestamp)
  ORDER BY time
  ```

- **Row 5 - Asset Class Allocation Over Time**: A stacked area timeseries showing how allocation across asset classes changes:
  ```sql
  SELECT timestamp AS time,
    SUM(CASE WHEN instrument LIKE 'DI%' THEN ABS(weight) ELSE 0 END) AS "Rates",
    SUM(CASE WHEN instrument LIKE 'USD%' OR instrument LIKE 'NDF%' THEN ABS(weight) ELSE 0 END) AS "FX",
    SUM(CASE WHEN instrument LIKE 'NTN%' THEN ABS(weight) ELSE 0 END) AS "Inflation",
    SUM(CASE WHEN instrument LIKE 'CDS%' THEN ABS(weight) ELSE 0 END) AS "Sovereign"
  FROM portfolio_state
  WHERE $__timeFilter(timestamp)
  GROUP BY timestamp
  ORDER BY timestamp
  ```

All dashboard JSON files must be valid Grafana dashboard format with:
- `"schemaVersion": 39`
- `"timezone": "browser"`
- `"time": {"from": "now-7d", "to": "now"}`
- `"refresh": "15m"` (per user decision)
- Proper datasource references using `"uid": "timescaledb"` (matching the provisioned datasource)
  </action>
  <verify>
1. Run `python -c "import json; d=json.load(open('monitoring/grafana/dashboards/risk_dashboard.json')); print(f'Risk Dashboard: {len(d.get(\"panels\", []))} panels'); assert d.get('refresh') == '15m'"` — must succeed.
2. Run `python -c "import json; d=json.load(open('monitoring/grafana/dashboards/portfolio_performance.json')); print(f'Portfolio Performance: {len(d.get(\"panels\", []))} panels')"` — must succeed.
3. Run `python -c "import json, glob; files=glob.glob('monitoring/grafana/dashboards/*.json'); [json.load(open(f)) for f in files]; print(f'All {len(files)} dashboards are valid JSON')"` — must show 4 valid JSON files.
  </verify>
  <done>
Risk dashboard with VaR gauge dials (95%/99%/CVaR/drawdown), stress scenario bar chart, limit utilization bars, and VaR history timeline. Portfolio performance dashboard with summary stats, equity curve, strategy attribution pie chart, monthly returns, and asset class allocation over time. All dashboards use 15-minute auto-refresh and reference the provisioned TimescaleDB datasource.
  </done>
</task>

</tasks>

<verification>
1. All 4 dashboard JSON files parse as valid JSON
2. Each dashboard has `"refresh": "15m"` for auto-refresh
3. Docker Compose has grafana service on port 3002 under monitoring profile
4. Datasource provisioning YAML connects to timescaledb:5432 with correct credentials
5. Dashboard provisioner points to /var/lib/grafana/dashboards directory
</verification>

<success_criteria>
- Grafana Docker service runs at port 3002 under `monitoring` profile
- TimescaleDB datasource auto-provisions on first Grafana start
- 4 dashboard JSON files exist and are valid Grafana dashboard format
- Pipeline health: connector status grid (6 panels) + run timeline + error log
- Signal overview: heatmap table + conviction distribution + flip timeline
- Risk dashboard: VaR gauge dials + stress bar chart + limit utilization + VaR history
- Portfolio performance: equity curve + attribution pie + monthly heatmap + asset allocation
- All dashboards auto-refresh every 15 minutes
</success_criteria>

<output>
After completion, create `.planning/phases/18-dagster-orchestration-monitoring-reporting/18-03-SUMMARY.md`
</output>
