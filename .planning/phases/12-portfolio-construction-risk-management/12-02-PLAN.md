---
phase: 12-portfolio-construction-risk-management
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/risk/__init__.py
  - src/risk/var_calculator.py
  - src/risk/stress_tester.py
  - tests/test_risk/__init__.py
  - tests/test_risk/test_var_calculator.py
  - tests/test_risk/test_stress_tester.py
autonomous: true
requirements: [RISK-01, RISK-02, RISK-03, RISK-04]

must_haves:
  truths:
    - "VaRCalculator computes historical VaR at 95% and 99% confidence from portfolio return series"
    - "VaRCalculator computes parametric VaR using Gaussian assumption with Ledoit-Wolf covariance"
    - "VaRCalculator computes Monte Carlo VaR using Student-t fitted marginals with Cholesky correlation"
    - "Expected Shortfall (CVaR) computed as conditional mean beyond VaR threshold for all methods"
    - "VaR requires minimum 252 observations for historical method; falls back to parametric with warning for shorter history"
    - "StressTester runs 4 historical replay scenarios (Taper Tantrum, BR Crisis, COVID, Rate Shock)"
    - "Stress test produces position-level and portfolio-level P&L impact"
    - "Stress tests are advisory only -- they report results but do not trigger position changes"
  artifacts:
    - path: "src/risk/var_calculator.py"
      provides: "VaRCalculator class with historical, parametric, and Monte Carlo VaR methods, plus CVaR"
      min_lines: 200
    - path: "src/risk/stress_tester.py"
      provides: "StressTester class with 4+ historical scenario definitions and replay logic"
      min_lines: 150
    - path: "tests/test_risk/test_var_calculator.py"
      provides: "Unit tests for all VaR methods and CVaR"
      min_lines: 120
    - path: "tests/test_risk/test_stress_tester.py"
      provides: "Unit tests for stress scenario application and P&L computation"
      min_lines: 80
  key_links:
    - from: "src/risk/var_calculator.py"
      to: "scipy.stats"
      via: "imports norm, t for distribution fitting and quantile"
      pattern: "from scipy import stats"
    - from: "src/risk/var_calculator.py"
      to: "sklearn.covariance"
      via: "imports LedoitWolf for robust covariance estimation"
      pattern: "from sklearn\\.covariance import LedoitWolf"
    - from: "src/risk/stress_tester.py"
      to: "src/risk/var_calculator.py"
      via: "same package, independent module"
      pattern: "StressScenario.*StressResult"
---

<objective>
Build the quantitative risk computation engine: VaRCalculator (historical VaR, parametric VaR, Monte Carlo VaR with t-distribution fitting, and Expected Shortfall/CVaR for all methods) and StressTester (4 historical crisis replay scenarios with position-level P&L impact reporting).

Purpose: These are the core quantitative risk metrics that feed into the RiskMonitor (Plan 12-03). VaR/CVaR quantifies daily portfolio risk, while stress tests reveal vulnerability to crisis scenarios. Both are essential for the risk report and capital allocation decisions.

Output: New `src/risk/` package with `var_calculator.py` and `stress_tester.py`, plus comprehensive unit tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-portfolio-construction-risk-management/12-CONTEXT.md
@.planning/phases/12-portfolio-construction-risk-management/12-RESEARCH.md

# Key upstream source files
@src/backtesting/metrics.py
@src/backtesting/portfolio.py
@src/core/enums.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: VaRCalculator with historical, parametric, and Monte Carlo methods</name>
  <files>
    src/risk/__init__.py
    src/risk/var_calculator.py
    tests/test_risk/__init__.py
    tests/test_risk/test_var_calculator.py
  </files>
  <action>
Create `src/risk/` package with `__init__.py` and `var_calculator.py`.

**var_calculator.py — VaRCalculator class (RISK-01, RISK-02, RISK-03):**

1. Define `VaRResult` dataclass:
   - `var_95: float` — 95% VaR (1-day) as a negative percentage
   - `var_99: float` — 99% VaR (1-day) as a negative percentage
   - `cvar_95: float` — 95% CVaR (Expected Shortfall)
   - `cvar_99: float` — 99% CVaR (Expected Shortfall)
   - `method: str` — "historical", "parametric", or "monte_carlo"
   - `n_observations: int` — number of return observations used
   - `confidence_warning: str | None` — warning if insufficient data
   - `timestamp: datetime`

2. Pure function `compute_historical_var(returns: np.ndarray, confidence: float = 0.95) -> tuple[float, float]`:
   - If len(returns) < 10, return (0.0, 0.0)
   - VaR = np.percentile(returns, (1 - confidence) * 100)
   - CVaR = mean of returns <= VaR (if any tail observations exist, else VaR)
   - Return (var, cvar) — both negative numbers representing losses

3. Pure function `compute_parametric_var(returns: np.ndarray, confidence: float = 0.95) -> tuple[float, float]`:
   - Compute mean and std of returns
   - VaR = mean + std * scipy.stats.norm.ppf(1 - confidence) — note: ppf at low alpha gives negative z-score
   - CVaR = mean - std * scipy.stats.norm.pdf(scipy.stats.norm.ppf(1 - confidence)) / (1 - confidence) — analytical formula for Gaussian CVaR
   - Return (var, cvar)

4. Pure function `compute_monte_carlo_var(returns_matrix: np.ndarray, weights: np.ndarray, confidence: float = 0.95, n_simulations: int = 10_000) -> tuple[float, float]`:
   - Step 1: Fit Student-t distribution to each asset's returns via `scipy.stats.t.fit()`. If fitting fails (< 30 obs), fall back to normal (df=inf, loc=mean, scale=std).
   - Step 2: Estimate correlation matrix using `sklearn.covariance.LedoitWolf`. Convert covariance to correlation via dividing by outer product of standard deviations. Fill diagonal with 1.0.
   - Step 3: Cholesky decomposition of correlation matrix via `np.linalg.cholesky`. If it fails (non-positive-definite), clamp eigenvalues to `max(eigenvalue, 1e-8)` and retry (eigenvalue floor pitfall from RESEARCH.md).
   - Step 4: Generate n_simulations x n_assets standard normal samples, multiply by Cholesky lower triangle to get correlated normals.
   - Step 5: Transform to uniform via `scipy.stats.norm.cdf`, then to t-distributed marginals via `scipy.stats.t.ppf` with fitted parameters.
   - Step 6: Compute simulated portfolio returns = sim_returns @ weights. Extract VaR and CVaR via np.percentile and conditional mean.
   - Use `np.random.default_rng(seed=42)` for reproducibility in tests (accept optional `rng` parameter).
   - Return (var, cvar)

5. `VaRCalculator.__init__(self, min_historical_obs: int = 252, mc_simulations: int = 10_000)`:
   - Store configuration parameters.

6. `VaRCalculator.calculate(self, portfolio_returns: np.ndarray, method: str = "historical") -> VaRResult`:
   - Validate inputs: returns must be 1D array for historical/parametric, or provide returns_matrix + weights for monte_carlo.
   - For "historical": require >= min_historical_obs observations. If insufficient, fall back to parametric with confidence_warning.
   - Compute VaR at both 95% and 99% confidence levels.
   - Return VaRResult with all fields.

7. `VaRCalculator.calculate_monte_carlo(self, returns_matrix: np.ndarray, weights: np.ndarray) -> VaRResult`:
   - Convenience method for Monte Carlo VaR. Calls compute_monte_carlo_var for 95% and 99%.
   - Return VaRResult with method="monte_carlo".

8. `VaRCalculator.calculate_all_methods(self, portfolio_returns: np.ndarray, returns_matrix: np.ndarray | None = None, weights: np.ndarray | None = None) -> dict[str, VaRResult]`:
   - Run all available methods and return dict keyed by method name. Monte Carlo only if returns_matrix and weights provided.

Use structlog for logging. All functions are pure computation — no I/O or database.

**Unit tests — test_var_calculator.py:**
- test_historical_var_known_values: hand-computed VaR for [0.01, -0.02, 0.005, -0.03, ...] ~100 values. Verify np.percentile matches.
- test_historical_cvar_is_tail_mean: CVaR should be mean of returns below VaR threshold.
- test_parametric_var_standard_normal: for N(0, 0.01) returns, VaR_95 ~ -0.0165 (check within tolerance).
- test_parametric_cvar_below_var: CVaR magnitude > VaR magnitude for Gaussian.
- test_monte_carlo_var_produces_result: returns_matrix (250, 3) with weights [0.4, 0.3, 0.3]. VaR should be negative. Use fixed seed for reproducibility.
- test_monte_carlo_cvar_worse_than_var: CVaR <= VaR (more negative = worse).
- test_historical_fallback_short_history: 100 observations (< 252) -> falls back to parametric, confidence_warning set.
- test_var_empty_returns: empty array -> (0.0, 0.0).
- test_monte_carlo_singular_covariance: near-singular returns matrix -> eigenvalue floor applied, no crash.
- test_calculate_all_methods: returns dict with "historical" and "parametric" keys. Monte Carlo included when matrix provided.
- test_var_99_more_extreme_than_95: |VaR_99| > |VaR_95| for non-trivial returns.

Run: `python -m pytest tests/test_risk/test_var_calculator.py -v`
  </action>
  <verify>
    - `python -m pytest tests/test_risk/test_var_calculator.py -v` — all tests pass
    - `python -c "from src.risk.var_calculator import VaRCalculator, VaRResult; print('OK')"` succeeds
    - `ruff check src/risk/var_calculator.py tests/test_risk/test_var_calculator.py` — zero errors
  </verify>
  <done>
    - Historical VaR at 95% and 99% computed correctly for known return series
    - Parametric VaR uses Gaussian assumption with analytical CVaR formula
    - Monte Carlo VaR fits Student-t marginals with Cholesky-correlated draws
    - CVaR (Expected Shortfall) computed for all methods as conditional mean beyond VaR
    - Short history fallback to parametric with warning
    - Singular covariance handled via eigenvalue floor
    - All ~11 unit tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: StressTester with 4 historical scenarios, package exports, and stress tests</name>
  <files>
    src/risk/stress_tester.py
    src/risk/__init__.py
    tests/test_risk/test_stress_tester.py
  </files>
  <action>
**stress_tester.py — StressTester class (RISK-04):**

1. Define `StressScenario` frozen dataclass:
   - `name: str` — scenario name (e.g., "Taper Tantrum 2013")
   - `description: str` — brief narrative
   - `shocks: dict[str, float]` — {instrument_id: pct_move}. E.g., {"USDBRL": 0.15} means +15% move.
   - `historical_period: str` — e.g., "May 2013 - Aug 2013"

2. Define `StressResult` dataclass:
   - `scenario_name: str`
   - `portfolio_pnl: float` — total portfolio P&L from scenario
   - `portfolio_pnl_pct: float` — P&L as percentage of portfolio value
   - `position_pnl: dict[str, float]` — {instrument: P&L}
   - `worst_position: str` — instrument with largest loss
   - `worst_position_pnl: float` — loss of worst position
   - `positions_impacted: int` — count of positions with non-zero shock
   - `positions_unaffected: int` — count of positions with no applicable shock
   - `timestamp: datetime`

3. Define `DEFAULT_SCENARIOS: list[StressScenario]` — 4 locked historical scenarios (from RESEARCH.md):

   **Taper Tantrum 2013** (May-Aug 2013):
   - USDBRL: +0.15, DI_PRE: +0.02 (200bps as rate change), NTN_B_REAL: -0.08, IBOVESPA: -0.15, UST_NOM: +0.01

   **BR Crisis 2015** (Sep 2015 - Feb 2016):
   - USDBRL: +0.30, DI_PRE: +0.04 (400bps), NTN_B_REAL: -0.15, IBOVESPA: -0.25

   **COVID 2020** (Feb-Mar 2020):
   - USDBRL: +0.20, DI_PRE: +0.02 (200bps), IBOVESPA: -0.35, SP500: -0.30, OIL: -0.50

   **Rate Shock 2022** (Oct-Nov 2022):
   - USDBRL: +0.25, DI_PRE: +0.05 (500bps), NTN_B_REAL: -0.12

   Note: Shocks use the same instrument ID convention as strategies (DI_PRE, USDBRL, etc.). For DI-related positions, apply shocks to any instrument starting with "DI_PRE" (partial match). This handles tenor-specific instruments like DI_PRE_365.

4. `StressTester.__init__(self, scenarios: list[StressScenario] | None = None)`:
   - Defaults to DEFAULT_SCENARIOS if None.

5. `StressTester.run_scenario(self, positions: dict[str, float], scenario: StressScenario, portfolio_value: float | None = None) -> StressResult`:
   - For each position (instrument -> notional):
     - Look up shock in scenario.shocks. Use exact match first, then prefix match (e.g., "DI_PRE_365" matches "DI_PRE" if exact not found).
     - position_pnl = notional * shock
   - Sum all position P&Ls for portfolio_pnl.
   - portfolio_pnl_pct = portfolio_pnl / portfolio_value if portfolio_value provided, else portfolio_pnl / sum(abs(positions.values())) as approximation.
   - Identify worst_position (most negative P&L).
   - Count impacted vs unaffected positions.
   - Log warning if > 50% of positions have no applicable shock (from RESEARCH.md recommendation).
   - Return StressResult. Stress tests are advisory only (locked decision) — no position changes.

6. `StressTester.run_all(self, positions: dict[str, float], portfolio_value: float | None = None) -> list[StressResult]`:
   - Run all scenarios and return list of StressResult.

7. `StressTester.worst_case(self, results: list[StressResult]) -> StressResult`:
   - Return the scenario with the most negative portfolio_pnl.

**Update __init__.py:**
Export VaRCalculator, VaRResult, StressTester, StressScenario, StressResult, DEFAULT_SCENARIOS.

**Unit tests — test_stress_tester.py:**
- test_single_scenario_known_pnl: portfolio with USDBRL=100K notional, Taper Tantrum shock +15% -> pnl = +15K (long position benefits from USDBRL up)
- test_single_scenario_short_position: USDBRL=-100K notional, +15% shock -> pnl = -15K (short position loses)
- test_no_matching_shock: position in instrument not in scenario -> zero P&L for that position
- test_prefix_matching_di_pre: DI_PRE_365 position matches DI_PRE shock
- test_run_all_returns_4_results: default scenarios -> 4 StressResult objects
- test_worst_case_selection: worst_case returns scenario with most negative portfolio P&L
- test_portfolio_pnl_pct: verify percentage calculation against known portfolio value
- test_advisory_only_no_side_effects: stress test does not modify input positions dict
- test_worst_position_identified: correctly identifies instrument with largest loss
- test_empty_positions: empty portfolio -> zero P&L for all scenarios

Run: `python -m pytest tests/test_risk/test_stress_tester.py -v`
  </action>
  <verify>
    - `python -m pytest tests/test_risk/ -v` — all tests pass (VaR + stress)
    - `python -c "from src.risk import VaRCalculator, StressTester, DEFAULT_SCENARIOS; print(f'{len(DEFAULT_SCENARIOS)} scenarios'); print('OK')"` succeeds
    - `ruff check src/risk/ tests/test_risk/` — zero errors
  </verify>
  <done>
    - StressTester.run_all() replays 4 historical scenarios with correct shock application
    - Position-level P&L computed for each instrument per scenario
    - Prefix matching for DI_PRE instruments handles tenor-specific positions
    - Stress results are advisory only (no side effects on positions)
    - All ~10 stress test unit tests + ~11 VaR unit tests = ~21 total tests pass
    - Package exports all classes from src/risk/
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/test_risk/ -v` — all ~21 tests pass
2. `python -c "from src.risk import VaRCalculator, VaRResult, StressTester, StressScenario, StressResult, DEFAULT_SCENARIOS; print('All exports OK')"` succeeds
3. `ruff check src/risk/ tests/test_risk/` — zero errors
4. Verify VaR_99 is more extreme (more negative) than VaR_95 for a test case
5. Verify CVaR is more extreme (more negative) than VaR for all methods
6. Verify 4 default stress scenarios are defined with correct instrument shocks
</verification>

<success_criteria>
- VaRCalculator produces correct VaR/CVaR at 95% and 99% for historical, parametric, and Monte Carlo methods
- Monte Carlo uses Student-t marginals with Cholesky correlation (not Gaussian)
- StressTester replays 4 historical crisis scenarios with position-level P&L
- Stress tests are advisory only — no automatic position changes (locked decision)
- All code is pure computation (no database, no I/O)
- ~21 unit tests pass, zero lint errors
</success_criteria>

<output>
After completion, create `.planning/phases/12-portfolio-construction-risk-management/12-02-SUMMARY.md`
</output>
