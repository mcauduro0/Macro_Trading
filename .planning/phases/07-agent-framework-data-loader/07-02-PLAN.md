---
phase: 07-agent-framework-data-loader
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - src/agents/registry.py
  - src/core/models/agent_reports.py
  - src/core/models/__init__.py
  - alembic/env.py
  - alembic/versions/003_add_agent_reports_table.py
  - src/agents/__init__.py
  - tests/test_agents/__init__.py
  - tests/test_agents/test_base.py
  - tests/test_agents/test_data_loader.py
  - tests/test_agents/test_registry.py
autonomous: true
requirements: [AGENT-05, AGENT-06, AGENT-07]

must_haves:
  truths:
    - "AgentRegistry.run_all(as_of_date) executes agents in dependency order and returns dict of AgentReports"
    - "Signals persist to the signals hypertable via ON CONFLICT DO NOTHING"
    - "agent_reports table exists in the database after running alembic upgrade head"
    - "Tests verify BaseAgent contract, PointInTimeDataLoader queries, and AgentRegistry execution order"
  artifacts:
    - path: "src/agents/registry.py"
      provides: "AgentRegistry with register, get, run_all methods"
      min_lines: 40
    - path: "src/core/models/agent_reports.py"
      provides: "AgentReportRecord ORM model for persistence"
      min_lines: 25
    - path: "alembic/versions/003_add_agent_reports_table.py"
      provides: "Migration creating agent_reports table"
      contains: "agent_reports"
    - path: "tests/test_agents/test_base.py"
      provides: "Unit tests for BaseAgent, AgentSignal, classify_strength"
      min_lines: 60
    - path: "tests/test_agents/test_data_loader.py"
      provides: "Tests for PointInTimeDataLoader PIT queries"
      min_lines: 40
    - path: "tests/test_agents/test_registry.py"
      provides: "Tests for AgentRegistry ordered execution"
      min_lines: 40
  key_links:
    - from: "src/agents/registry.py"
      to: "src/agents/base.py"
      via: "import BaseAgent, AgentReport"
      pattern: "from src\\.agents\\.base import"
    - from: "src/core/models/agent_reports.py"
      to: "src/core/models/base.py"
      via: "inherits from Base"
      pattern: "from \\.base import Base"
    - from: "alembic/env.py"
      to: "src/core/models/agent_reports.py"
      via: "import for autogenerate detection"
      pattern: "agent_reports"
    - from: "tests/test_agents/test_base.py"
      to: "src/agents/base.py"
      via: "tests BaseAgent, AgentSignal, AgentReport"
      pattern: "from src\\.agents\\.base import"
---

<objective>
Complete the agent framework with AgentRegistry (ordered execution), signal persistence wiring, Alembic migration for agent_reports table, and comprehensive tests validating the entire framework.

Purpose: AgentRegistry enables the daily pipeline to run all agents in one call. The agent_reports table provides audit trail storage. Tests ensure the framework contract is correct before agents are built on it in Phases 8-10.
Output: src/agents/registry.py, src/core/models/agent_reports.py, Alembic migration 003, tests in tests/test_agents/
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-agent-framework-data-loader/07-RESEARCH.md
@.planning/phases/07-agent-framework-data-loader/07-01-SUMMARY.md

@src/agents/base.py
@src/agents/data_loader.py
@src/agents/__init__.py
@src/core/models/__init__.py
@src/core/models/base.py
@src/core/models/signals.py
@src/core/database.py
@src/connectors/base.py
@alembic/env.py
@alembic/versions/002_add_instrument_type_contract_specs.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AgentRegistry, AgentReportRecord ORM model, Alembic migration, and update imports</name>
  <files>
    src/agents/registry.py
    src/core/models/agent_reports.py
    src/core/models/__init__.py
    alembic/env.py
    alembic/versions/003_add_agent_reports_table.py
    src/agents/__init__.py
  </files>
  <action>
**Step 1: Create src/agents/registry.py -- AgentRegistry**

```python
"""Agent registry and orchestration for the Macro Trading system.

Manages registration, lookup, and ordered execution of all analytical agents.
Execution order: inflation -> monetary -> fiscal -> fx -> cross_asset
"""
```

Imports: `from datetime import date`, `structlog`, `from src.agents.base import BaseAgent, AgentReport`

Class `AgentRegistry`:
- Class-level `_agents: dict[str, BaseAgent] = {}` -- stores registered agents by agent_id.
- Class-level `EXECUTION_ORDER: list[str] = ["inflation_agent", "monetary_agent", "fiscal_agent", "fx_agent", "cross_asset_agent"]` -- defines dependency order.

Methods (all `@classmethod`):
- `register(cls, agent: BaseAgent) -> None`: Add agent to `_agents` dict keyed by `agent.agent_id`. Log: `structlog.get_logger().info("agent_registered", agent_id=agent.agent_id, agent_name=agent.agent_name)`. Raise `ValueError` if agent_id already registered.
- `unregister(cls, agent_id: str) -> None`: Remove agent from `_agents`. Raise `KeyError` if not found.
- `get(cls, agent_id: str) -> BaseAgent`: Return agent by id. Raise `KeyError` with helpful message if not found.
- `list_registered(cls) -> list[str]`: Return sorted list of registered agent_ids.
- `run_all(cls, as_of_date: date) -> dict[str, AgentReport]`: Execute all registered agents in EXECUTION_ORDER. For each agent_id in EXECUTION_ORDER, if that agent_id is in `_agents`, call `agent.run(as_of_date)` and store the result. Agents not in EXECUTION_ORDER but registered are run AFTER the ordered ones (alphabetically). Return `{agent_id: AgentReport}`. Wrap each agent run in try/except, log errors, and continue with remaining agents -- do NOT let one agent failure abort all.
- `run_all_backtest(cls, as_of_date: date) -> dict[str, AgentReport]`: Same as run_all but calls `agent.backtest_run(as_of_date)` instead -- no signal persistence.
- `clear(cls) -> None`: Clear all registered agents. Useful for testing.

**Step 2: Create src/core/models/agent_reports.py -- AgentReportRecord ORM model**

This is the SQLAlchemy 2.0 ORM model for persisting agent reports. Named `AgentReportRecord` (NOT `AgentReport`) to avoid confusion with the dataclass in `src/agents/base.py`.

Follow existing model patterns (mapped_column, Base inheritance):

```python
"""Agent reports table -- audit trail for agent execution results.

Regular PostgreSQL table (NOT a hypertable -- low volume: ~5 records/day).
Stores the narrative, diagnostics, and metadata from each agent run.
Individual signal values are persisted separately to the signals hypertable.
"""

from datetime import date, datetime
from typing import Optional

from sqlalchemy import Date, DateTime, Integer, String, Text, func
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.orm import Mapped, mapped_column

from .base import Base


class AgentReportRecord(Base):
    __tablename__ = "agent_reports"

    id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)
    agent_id: Mapped[str] = mapped_column(String(50), nullable=False)
    as_of_date: Mapped[date] = mapped_column(Date, nullable=False)
    signals_count: Mapped[int] = mapped_column(Integer, nullable=False, default=0)
    narrative: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
    model_diagnostics: Mapped[Optional[dict]] = mapped_column(JSONB, nullable=True)
    data_quality_flags: Mapped[Optional[list]] = mapped_column(JSONB, nullable=True)
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now()
    )

    __table_args__ = (
        # Not a unique constraint -- same agent can be re-run for the same date
        # (e.g., manual re-run after data correction)
    )
```

**Step 3: Update src/core/models/__init__.py** -- Add `AgentReportRecord` to imports and `__all__`:

Add at the end of imports:
```python
from .agent_reports import AgentReportRecord
```
Add `"AgentReportRecord"` to `__all__` list.

**Step 4: Update alembic/env.py** -- Add agent_reports import so autogenerate detects it:

In the model imports block (after the existing `signals` import), add:
```python
    agent_reports,
```

**Step 5: Create Alembic migration 003**

Run: `cd /home/user/Macro_Trading && alembic revision --autogenerate -m "add_agent_reports_table"`

This should detect the new `agent_reports` table. If autogenerate produces an empty migration, create it manually:

```python
"""add agent_reports table

Revision ID: c3d4e5f6g7h8
Revises: b2c3d4e5f6a7
Create Date: 2026-02-20
"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import JSONB

revision: str = "c3d4e5f6g7h8"
down_revision: Union[str, None] = "b2c3d4e5f6a7"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    op.create_table(
        "agent_reports",
        sa.Column("id", sa.Integer(), autoincrement=True, nullable=False),
        sa.Column("agent_id", sa.String(50), nullable=False),
        sa.Column("as_of_date", sa.Date(), nullable=False),
        sa.Column("signals_count", sa.Integer(), nullable=False, server_default="0"),
        sa.Column("narrative", sa.Text(), nullable=True),
        sa.Column("model_diagnostics", JSONB(), nullable=True),
        sa.Column("data_quality_flags", JSONB(), nullable=True),
        sa.Column("created_at", sa.DateTime(timezone=True), server_default=sa.func.now()),
        sa.PrimaryKeyConstraint("id", name="pk_agent_reports"),
    )
    op.create_index("ix_agent_reports_agent_id_date", "agent_reports", ["agent_id", "as_of_date"])


def downgrade() -> None:
    op.drop_index("ix_agent_reports_agent_id_date")
    op.drop_table("agent_reports")
```

After creating the migration file, run: `cd /home/user/Macro_Trading && alembic upgrade head`

Verify the table exists: `python -c "from src.core.database import sync_engine; from sqlalchemy import inspect; i = inspect(sync_engine); print('agent_reports' in i.get_table_names())"`

**Step 6: Update src/agents/__init__.py** -- Add AgentRegistry to exports:

Add import: `from src.agents.registry import AgentRegistry`
Add to `__all__`: `"AgentRegistry"`

**Step 7: Enhance BaseAgent._persist_signals to also persist AgentReport to agent_reports table**

Add a new concrete method to BaseAgent in `src/agents/base.py`:

```python
def _persist_report(self, report: AgentReport) -> None:
    """Persist agent report to agent_reports table for audit trail."""
    from src.core.models.agent_reports import AgentReportRecord
    session = sync_session_factory()
    try:
        record = AgentReportRecord(
            agent_id=report.agent_id,
            as_of_date=report.as_of_date,
            signals_count=len(report.signals),
            narrative=report.narrative,
            model_diagnostics=report.model_diagnostics or None,
            data_quality_flags=report.data_quality_flags or None,
        )
        session.add(record)
        session.commit()
        self.log.info("report_persisted", agent_id=report.agent_id, as_of_date=str(report.as_of_date))
    except Exception as e:
        session.rollback()
        self.log.error("report_persist_failed", error=str(e))
    finally:
        session.close()
```

Also update the `run()` method: after building the AgentReport and before returning, call `self._persist_report(report)`. The `backtest_run()` method should NOT call `_persist_report()`.

Add `from src.core.database import sync_session_factory` to the imports in base.py (if not already there for the _persist_signals method).
  </action>
  <verify>
Run these checks:
1. `cd /home/user/Macro_Trading && alembic upgrade head` -- migration succeeds
2. `python -c "from src.core.database import sync_engine; from sqlalchemy import inspect; i = inspect(sync_engine); print('agent_reports' in i.get_table_names())"` -- must print True
3. `python -c "from src.agents.registry import AgentRegistry; print(AgentRegistry.EXECUTION_ORDER)"` -- must print the 5 agent IDs
4. `python -c "from src.agents import AgentRegistry; AgentRegistry.clear(); print(AgentRegistry.list_registered())"` -- must print empty list
5. `python -c "from src.core.models import AgentReportRecord; print(AgentReportRecord.__tablename__)"` -- must print "agent_reports"
6. `ruff check src/agents/ src/core/models/agent_reports.py alembic/env.py` -- no errors
  </verify>
  <done>
AgentRegistry has register, unregister, get, list_registered, run_all, run_all_backtest, and clear methods. EXECUTION_ORDER defines inflation -> monetary -> fiscal -> fx -> cross_asset. AgentReportRecord ORM model exists with agent_id, as_of_date, signals_count, narrative, model_diagnostics, data_quality_flags columns. Alembic migration 003 creates agent_reports table. BaseAgent.run() persists both signals (to signals hypertable) and report (to agent_reports table). BaseAgent.backtest_run() persists neither.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write comprehensive tests for the agent framework</name>
  <files>
    tests/test_agents/__init__.py
    tests/test_agents/test_base.py
    tests/test_agents/test_data_loader.py
    tests/test_agents/test_registry.py
  </files>
  <action>
Create `tests/test_agents/__init__.py` as empty file.

**tests/test_agents/test_base.py -- BaseAgent, AgentSignal, AgentReport tests:**

```python
"""Tests for BaseAgent ABC, AgentSignal, AgentReport, and classify_strength."""
```

Imports: pytest, date, datetime, BaseAgent, AgentSignal, AgentReport, classify_strength from src.agents.base, SignalDirection, SignalStrength from src.core.enums.

1. **test_classify_strength_strong**: `assert classify_strength(0.75) == SignalStrength.STRONG`; `assert classify_strength(0.99) == SignalStrength.STRONG`
2. **test_classify_strength_moderate**: `assert classify_strength(0.50) == SignalStrength.MODERATE`; `assert classify_strength(0.74) == SignalStrength.MODERATE`
3. **test_classify_strength_weak**: `assert classify_strength(0.25) == SignalStrength.WEAK`; `assert classify_strength(0.49) == SignalStrength.WEAK`
4. **test_classify_strength_no_signal**: `assert classify_strength(0.0) == SignalStrength.NO_SIGNAL`; `assert classify_strength(0.24) == SignalStrength.NO_SIGNAL`
5. **test_agent_signal_creation**: Create an AgentSignal with all fields, verify all attributes are accessible and have correct types.
6. **test_agent_signal_default_metadata**: Create AgentSignal without setting metadata, verify `metadata == {}`.
7. **test_agent_report_creation**: Create AgentReport with list of signals, verify signals_count matches len(signals).
8. **test_base_agent_cannot_instantiate**: `with pytest.raises(TypeError): BaseAgent("test", "Test Agent")` -- ABC cannot be instantiated directly.
9. **test_concrete_agent_run**: Create a `DummyAgent(BaseAgent)` that implements all 4 abstract methods:
   - `load_data` returns `{"series_a": None}`
   - `compute_features` returns `{"feature_1": 1.0}`
   - `run_models` returns `[AgentSignal(signal_id="TEST", agent_id="dummy", timestamp=datetime.utcnow(), as_of_date=as_of_date, direction=SignalDirection.LONG, strength=SignalStrength.MODERATE, confidence=0.6, value=1.2, horizon_days=63)]`
   - `generate_narrative` returns "Test narrative"
   - Override `_persist_signals` to be a no-op (avoid DB in unit tests)
   - Override `_persist_report` to be a no-op
   Call `report = DummyAgent("dummy", "Dummy Agent").backtest_run(date(2024, 6, 15))`. Verify: report.agent_id == "dummy", len(report.signals) == 1, report.narrative == "Test narrative", report.signals[0].direction == SignalDirection.LONG.
10. **test_check_data_quality_flags_none**: DummyAgent._check_data_quality({"key": None}) returns ["key: data is None"].
11. **test_signal_direction_serializable**: `assert SignalDirection.LONG.value == "LONG"` and `assert str(SignalDirection.LONG) == "SignalDirection.LONG"`.

**tests/test_agents/test_data_loader.py -- PointInTimeDataLoader tests:**

```python
"""Tests for PointInTimeDataLoader PIT-correct queries.

These tests require a running database with seeded data from v1.0.
Mark as integration tests that can be skipped if DB is unavailable.
"""
```

Use `@pytest.mark.skipif` with a helper that checks DB connectivity.

Helper function at top of file:
```python
def _db_available() -> bool:
    try:
        from src.core.database import sync_engine
        with sync_engine.connect() as conn:
            conn.execute(sa.text("SELECT 1"))
        return True
    except Exception:
        return False

skip_no_db = pytest.mark.skipif(not _db_available(), reason="Database not available")
```

1. **test_loader_instantiation**: `loader = PointInTimeDataLoader()` -- no error.
2. **test_loader_has_all_methods**: Verify all 7 methods exist via `hasattr`.
3. **@skip_no_db test_get_macro_series_returns_dataframe**: Load "BR_SELIC_TARGET" for date(2024, 6, 15). Assert result is a DataFrame. Assert columns include "date" and "value". Assert len > 0 (Selic has daily data). Assert all dates in result <= date(2024, 6, 15).
4. **@skip_no_db test_get_macro_series_pit_correctness**: Load a series for date(2020, 1, 1). Then load for date(2024, 1, 1). The later query should have more rows (more data released by that date).
5. **@skip_no_db test_get_macro_series_empty**: Load a non-existent series code "NONEXISTENT_SERIES". Assert empty DataFrame returned.
6. **@skip_no_db test_get_latest_macro_value**: Get latest value for "BR_SELIC_TARGET" as of date(2024, 6, 15). Assert result is a float (not None).
7. **@skip_no_db test_get_curve_returns_dict**: Load curve "DI_PRE" for date(2024, 6, 15). Assert result is a dict. Assert len > 0 (DI curve has multiple tenors). Assert all keys are ints (tenor_days) and all values are floats (rates).
8. **@skip_no_db test_get_market_data_returns_dataframe**: Load "USDBRL" for date(2024, 6, 15). Assert DataFrame with columns including "close". Assert len > 0.
9. **@skip_no_db test_get_market_data_empty**: Load non-existent ticker. Assert empty DataFrame.

**tests/test_agents/test_registry.py -- AgentRegistry tests:**

```python
"""Tests for AgentRegistry ordered execution."""
```

Use the DummyAgent pattern from test_base.py. Create multiple DummyAgent subclasses with different agent_ids.

1. **test_register_and_get**: Register a DummyAgent, then get it back by id. Verify same instance.
2. **test_register_duplicate_raises**: Register an agent, then try to register another with the same id. Assert `ValueError`.
3. **test_unregister**: Register, then unregister. Assert agent_id not in list_registered.
4. **test_list_registered**: Register 3 agents, verify list_registered returns all 3 (sorted).
5. **test_run_all_execution_order**: Create agents with ids matching EXECUTION_ORDER (inflation_agent, monetary_agent, fiscal_agent). Each agent's run_models appends its agent_id to a shared list (use a module-level list). After run_all_backtest, verify the shared list has agents in the correct order (inflation first, then monetary, then fiscal).
6. **test_run_all_continues_on_error**: Create an ErrorAgent that raises Exception in run_models. Register it alongside a working DummyAgent. run_all_backtest should return the DummyAgent's report and skip the ErrorAgent without crashing.
7. **test_clear**: Register agents, call clear, verify list_registered is empty.

Use `AgentRegistry.clear()` in a pytest fixture (`autouse=True` or in setUp) to ensure test isolation -- each test starts with a clean registry.

Important: Override `_persist_signals` and `_persist_report` in all test agents to be no-ops, since tests should not touch the database for signal persistence.
  </action>
  <verify>
Run the tests:
1. `cd /home/user/Macro_Trading && python -m pytest tests/test_agents/test_base.py -v` -- all tests pass
2. `cd /home/user/Macro_Trading && python -m pytest tests/test_agents/test_registry.py -v` -- all tests pass
3. `cd /home/user/Macro_Trading && python -m pytest tests/test_agents/test_data_loader.py -v` -- tests pass (DB tests skipped if DB unavailable)
4. `cd /home/user/Macro_Trading && python -m pytest tests/test_agents/ -v` -- full suite passes
5. `ruff check tests/test_agents/` -- no lint errors
  </verify>
  <done>
test_base.py covers: classify_strength (4 buckets), AgentSignal creation and defaults, AgentReport creation, BaseAgent ABC enforcement, concrete DummyAgent with backtest_run, data quality flag detection. test_data_loader.py covers: instantiation, method presence, PIT macro_series query, PIT correctness (later dates have more data), empty results, latest_macro_value, curve loading, market_data loading. test_registry.py covers: register/get roundtrip, duplicate rejection, unregister, list_registered, run_all execution order verification, error resilience, clear isolation. All tests pass.
  </done>
</task>

</tasks>

<verification>
Full framework validation after both tasks:
1. `cd /home/user/Macro_Trading && python -m pytest tests/test_agents/ -v` -- all tests pass
2. `cd /home/user/Macro_Trading && alembic upgrade head && python -c "
from src.core.database import sync_engine
from sqlalchemy import inspect
i = inspect(sync_engine)
tables = i.get_table_names()
assert 'agent_reports' in tables, 'agent_reports table missing'
print('Migration verified: agent_reports table exists')
"` -- table verified
3. `python -c "
from src.agents import BaseAgent, AgentSignal, AgentReport, PointInTimeDataLoader, AgentRegistry
print('Framework complete:')
print(f'  BaseAgent: {BaseAgent.__abstractmethods__}')
print(f'  AgentRegistry order: {AgentRegistry.EXECUTION_ORDER}')
print(f'  Loader methods: {[m for m in dir(PointInTimeDataLoader) if not m.startswith(\"_\")]}')
"` -- shows complete framework
4. `ruff check src/agents/ src/core/models/agent_reports.py tests/test_agents/` -- no lint errors
</verification>

<success_criteria>
1. AgentRegistry.run_all(as_of_date) executes agents in EXECUTION_ORDER and returns dict[str, AgentReport]
2. AgentRegistry.run_all continues if one agent fails, logging the error
3. Signal persistence uses ON CONFLICT DO NOTHING on uq_signals_natural_key constraint
4. agent_reports table exists with columns: agent_id, as_of_date, signals_count, narrative, model_diagnostics (JSONB), data_quality_flags (JSONB), created_at
5. BaseAgent.run() persists both signals and report; backtest_run() persists neither
6. Tests verify: classify_strength correctness, AgentSignal dataclass, BaseAgent contract, DummyAgent execution, PointInTimeDataLoader queries with PIT filtering, AgentRegistry execution order, error resilience
7. All code passes ruff linting
</success_criteria>

<output>
After completion, create `.planning/phases/07-agent-framework-data-loader/07-02-SUMMARY.md`
</output>
