---
phase: 14-backtesting-engine-v2-strategy-framework
plan: 03
type: execute
wave: 3
depends_on:
  - 14-01
  - 14-02
files_modified:
  - src/backtesting/analytics.py
  - src/backtesting/metrics.py
  - src/backtesting/__init__.py
  - tests/test_backtesting_analytics.py
autonomous: true
requirements:
  - BTST-03
  - BTST-05
  - BTST-06

must_haves:
  truths:
    - "User can compute deflated Sharpe ratio that adjusts for multiple testing bias"
    - "User can compute Sortino ratio, information ratio, tail ratio, turnover, and rolling Sharpe from return arrays"
    - "User can call generate_tearsheet(result) and get a complete dict with equity_curve, drawdown_chart, monthly_heatmap, rolling_sharpe, trade_analysis"
    - "All analytics functions accept numpy arrays and return numeric results"
  artifacts:
    - path: "src/backtesting/analytics.py"
      provides: "Analytics functions: compute_sortino, compute_information_ratio, compute_tail_ratio, compute_turnover, compute_rolling_sharpe, deflated_sharpe, generate_tearsheet"
      exports: ["compute_sortino", "compute_information_ratio", "compute_tail_ratio", "compute_turnover", "compute_rolling_sharpe", "deflated_sharpe", "generate_tearsheet"]
    - path: "tests/test_backtesting_analytics.py"
      provides: "Unit tests for all analytics functions"
      min_lines: 100
  key_links:
    - from: "src/backtesting/analytics.py"
      to: "src/backtesting/metrics.py"
      via: "generate_tearsheet takes BacktestResult as input"
      pattern: "from src\\.backtesting\\.metrics import BacktestResult"
    - from: "src/backtesting/__init__.py"
      to: "src/backtesting/analytics.py"
      via: "re-exports analytics functions"
      pattern: "from src\\.backtesting\\.analytics import"
---

<objective>
Deflated Sharpe ratio, expanded analytics suite (Sortino, information ratio, tail ratio, turnover, rolling Sharpe), and tearsheet generation for complete backtest reporting.

Purpose: Provide statistically rigorous performance measurement (deflated Sharpe adjusts for multiple testing bias per Bailey & Lopez de Prado 2014) and a complete tearsheet generator that produces all data needed for dashboard rendering -- equity curve, drawdown chart, monthly returns heatmap, rolling Sharpe, and trade analysis.

Output: New analytics.py with 7+ functions, updated __init__.py exports, and comprehensive tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-backtesting-engine-v2-strategy-framework/14-01-SUMMARY.md
@src/backtesting/metrics.py
@src/backtesting/__init__.py
@docs/GUIA_COMPLETO_CLAUDE_CODE_Fase2.md (lines 398-462 for analytics specs)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Analytics functions module with deflated Sharpe and expanded metrics</name>
  <files>
    src/backtesting/analytics.py
    src/backtesting/__init__.py
  </files>
  <action>
Create src/backtesting/analytics.py with the following functions. Use numpy for all computations. Each function should handle edge cases (empty arrays, zero variance, etc.) gracefully by returning 0.0.

1. **compute_sortino(returns: np.ndarray, target: float = 0.0) -> float** (BTST-05):
   Sortino ratio = (mean(returns) - target) * sqrt(252) / downside_std.
   Downside std uses only returns below target. If no downside returns or downside_std == 0, return 0.0.

2. **compute_information_ratio(returns: np.ndarray, benchmark: np.ndarray) -> float** (BTST-05):
   IR = mean(active_returns) * sqrt(252) / std(active_returns).
   active_returns = returns - benchmark. If std == 0, return 0.0.
   If arrays have different lengths, truncate to shorter.

3. **compute_tail_ratio(returns: np.ndarray, quantile: float = 0.05) -> float** (BTST-05):
   tail_ratio = |percentile(returns, 100*(1-quantile))| / |percentile(returns, 100*quantile)|.
   Measures asymmetry of tails. If denominator == 0, return 0.0.

4. **compute_turnover(positions: np.ndarray) -> float** (BTST-05):
   Average absolute change in positions per period.
   turnover = mean(|positions[t] - positions[t-1]|) for t > 0.
   If len(positions) < 2, return 0.0.

5. **compute_rolling_sharpe(returns: np.ndarray, window: int = 252) -> np.ndarray** (BTST-05):
   Rolling Sharpe ratio with given window. For each index i >= window-1:
   window_returns = returns[i-window+1:i+1]
   rolling_sharpe[i] = mean(window_returns) * sqrt(252) / std(window_returns)
   Return array of same length as returns, with NaN for indices < window-1.
   Handle zero std by returning 0.0 for that window.

6. **deflated_sharpe(observed_sharpe: float, n_trials: int, skewness: float, kurtosis_excess: float, n_observations: int, variance_of_sharpe_estimates: float | None = None) -> float** (BTST-03):
   Bailey & Lopez de Prado (2014) Deflated Sharpe Ratio.

   The DSR tests: H0: SR* = 0 vs H1: SR* > 0, adjusting for the fact that we selected the best Sharpe from n_trials trials.

   Implementation:
   a. Expected max Sharpe from i.i.d. trials (Euler-Mascheroni approximation):
      `E_max_SR = sqrt(variance_of_sharpe_estimates) * ((1 - gamma) * norm.ppf(1 - 1/n_trials) + gamma * norm.ppf(1 - 1/(n_trials * e)))` where gamma = Euler-Mascheroni constant = 0.5772...

      If variance_of_sharpe_estimates is None, estimate it as: `var_sr = (1 - skewness * observed_sharpe + (kurtosis_excess / 4) * observed_sharpe**2) / (n_observations - 1)`

   b. Deflated Sharpe = P(SR < observed_sharpe | SR* = E_max_SR):
      `PSR = norm.cdf((observed_sharpe - E_max_SR) * sqrt(n_observations - 1) / sqrt(var_sr * n_observations))`

   c. Return PSR (probability that the observed Sharpe is significant after adjusting for multiple testing). Values > 0.95 suggest the Sharpe is likely real, not a result of data mining.

   Guard: if n_trials <= 0 or n_observations <= 1, return 0.0.
   Use scipy.stats.norm for CDF computation.

7. **generate_tearsheet(result: BacktestResult) -> dict** (BTST-06):
   Produce a complete dict for dashboard rendering:
   ```python
   {
       "summary": {
           "strategy_id": str,
           "start_date": str, "end_date": str,
           "total_return": float, "annualized_return": float,
           "annualized_volatility": float,
           "sharpe_ratio": float, "sortino_ratio": float,
           "calmar_ratio": float, "max_drawdown": float,
           "win_rate": float, "profit_factor": float, "total_trades": int,
       },
       "equity_curve": [{"date": "YYYY-MM-DD", "equity": float}, ...],
       "drawdown_chart": [{"date": "YYYY-MM-DD", "drawdown_pct": float}, ...],
       "monthly_heatmap": {
           "years": [2020, 2021, ...],
           "data": [[jan_ret, feb_ret, ..., dec_ret, ytd_ret], ...]  # per year row
       },
       "rolling_sharpe": [{"date": "YYYY-MM-DD", "sharpe": float}, ...],
       "trade_analysis": {
           "total_trades": int,
           "winning_trades": int, "losing_trades": int,
           "win_rate": float, "avg_win": float, "avg_loss": float,
           "profit_factor": float, "largest_win": float, "largest_loss": float,
       },
       "return_distribution": {
           "mean": float, "std": float, "skewness": float, "kurtosis": float,
           "percentiles": {"5": float, "25": float, "50": float, "75": float, "95": float},
       },
   }
   ```

   Computation details:
   - equity_curve: Convert result.equity_curve list of (date, equity) tuples to list of dicts.
   - drawdown_chart: Compute drawdown series from equity curve (equity / rolling_max - 1) * 100.
   - monthly_heatmap: Parse result.monthly_returns dict. Group by year. Add YTD column (compound monthly returns).
   - rolling_sharpe: Compute from equity curve daily returns using compute_rolling_sharpe(window=63) for quarterly rolling. Convert to list of dicts with dates.
   - trade_analysis: Derive from result fields (win_rate, profit_factor, total_trades) plus compute avg_win, avg_loss from monthly_returns if trade-level data not available.
   - return_distribution: Compute from daily returns derived from equity curve. Use scipy.stats.skew and kurtosis if available, else numpy-based.

8. **Update src/backtesting/__init__.py**: Add imports for all analytics functions and generate_tearsheet. Add deflated_sharpe. Add them to __all__.
  </action>
  <verify>
    Run: `cd /home/user/Macro_Trading && python -c "
import numpy as np
from src.backtesting.analytics import (
    compute_sortino, compute_information_ratio, compute_tail_ratio,
    compute_turnover, compute_rolling_sharpe, deflated_sharpe,
    generate_tearsheet
)

# Basic smoke tests
returns = np.array([0.01, -0.005, 0.008, -0.002, 0.015, -0.01, 0.005])
assert isinstance(compute_sortino(returns), float)
assert isinstance(compute_information_ratio(returns, returns * 0.5), float)
assert isinstance(compute_tail_ratio(returns), float)
assert isinstance(compute_turnover(returns), float)

rs = compute_rolling_sharpe(returns, window=3)
assert len(rs) == len(returns)

dsr = deflated_sharpe(1.5, n_trials=10, skewness=0.1, kurtosis_excess=3.0, n_observations=252)
assert 0.0 <= dsr <= 1.0

# Verify generate_tearsheet import
from src.backtesting import generate_tearsheet as gt2
assert gt2 is generate_tearsheet

print('ALL CHECKS PASSED')
"`
  </verify>
  <done>analytics.py exports 7 functions: compute_sortino, compute_information_ratio, compute_tail_ratio, compute_turnover, compute_rolling_sharpe, deflated_sharpe, generate_tearsheet. All handle edge cases. deflated_sharpe implements Bailey & Lopez de Prado (2014) DSR. generate_tearsheet produces complete dict with 6 sections for dashboard rendering.</done>
</task>

<task type="auto">
  <name>Task 2: Comprehensive tests for analytics functions, deflated Sharpe, and tearsheet generation</name>
  <files>
    tests/test_backtesting_analytics.py
  </files>
  <action>
Create tests/test_backtesting_analytics.py with thorough tests for each analytics function:

1. **compute_sortino tests**:
   - `test_sortino_positive_returns_only`: All positive returns -> high Sortino (downside_std small or zero -> return 0.0 per guard).
   - `test_sortino_known_value`: Use returns [0.01, -0.02, 0.015, -0.005, 0.01]. Manually compute expected downside std and verify result is within tolerance.
   - `test_sortino_empty_returns`: np.array([]) -> 0.0.
   - `test_sortino_all_negative`: All negative returns -> negative Sortino.

2. **compute_information_ratio tests**:
   - `test_ir_identical_returns`: returns == benchmark -> IR = 0.0 (active returns all zero).
   - `test_ir_outperformance`: returns consistently > benchmark -> IR > 0.
   - `test_ir_different_lengths`: Verify truncation works (no crash).

3. **compute_tail_ratio tests**:
   - `test_tail_ratio_symmetric`: Returns from normal distribution -> tail_ratio close to 1.0.
   - `test_tail_ratio_positive_skew`: More large gains than losses -> tail_ratio > 1.0.
   - `test_tail_ratio_empty`: np.array([]) -> 0.0.

4. **compute_turnover tests**:
   - `test_turnover_constant_positions`: No change -> 0.0.
   - `test_turnover_alternating`: [1, -1, 1, -1] -> mean(|delta|) = 2.0.
   - `test_turnover_single`: [1.0] -> 0.0.

5. **compute_rolling_sharpe tests**:
   - `test_rolling_sharpe_output_length`: len(output) == len(input).
   - `test_rolling_sharpe_nans_at_start`: First window-1 values are NaN.
   - `test_rolling_sharpe_constant_returns`: Constant positive returns -> rolling Sharpe >> 0 (or capped/high).

6. **deflated_sharpe tests** (BTST-03):
   - `test_dsr_single_trial`: n_trials=1 -> DSR close to norm.cdf(observed_sharpe * sqrt(n_obs)) (no penalty).
   - `test_dsr_many_trials_reduces_significance`: With same observed_sharpe=2.0, DSR(n_trials=1) > DSR(n_trials=100). Multiple testing penalty reduces significance.
   - `test_dsr_range_0_to_1`: Assert 0.0 <= DSR <= 1.0 for various inputs.
   - `test_dsr_zero_trials_returns_zero`: n_trials=0 -> 0.0.
   - `test_dsr_low_sharpe_low_probability`: observed_sharpe=0.1, n_trials=50 -> DSR < 0.5.
   - `test_dsr_high_sharpe_high_probability`: observed_sharpe=3.0, n_trials=5, n_obs=1000 -> DSR > 0.8.

7. **generate_tearsheet tests** (BTST-06):
   - `test_tearsheet_structure`: Create a BacktestResult with known equity_curve and monthly_returns. Call generate_tearsheet. Assert all 6 top-level keys present: "summary", "equity_curve", "drawdown_chart", "monthly_heatmap", "rolling_sharpe", "trade_analysis", "return_distribution".
   - `test_tearsheet_equity_curve_format`: Each element has "date" and "equity" keys.
   - `test_tearsheet_drawdown_chart_values`: All drawdown_pct values <= 0.
   - `test_tearsheet_monthly_heatmap_structure`: Has "years" (list of ints) and "data" (list of lists).
   - `test_tearsheet_summary_fields`: summary dict has all expected keys (strategy_id, total_return, sharpe_ratio, etc.).
   - `test_tearsheet_empty_equity_curve`: Empty result -> still returns valid dict with empty lists/zero values.

Use a helper fixture that creates a realistic BacktestResult with a synthetic equity curve (e.g., 252 daily points from 1M to 1.1M with some volatility).
  </action>
  <verify>
    Run: `cd /home/user/Macro_Trading && python -m pytest tests/test_backtesting_analytics.py -v --tb=short 2>&1 | tail -40`
  </verify>
  <done>All tests pass. Sortino, information ratio, tail ratio, turnover, and rolling Sharpe tests verify correct computation and edge case handling. Deflated Sharpe tests verify DSR decreases with more trials (multiple testing penalty), stays in [0,1], and handles edge cases. Tearsheet tests verify complete dict structure with all 6/7 sections, correct formats, and graceful handling of empty inputs.</done>
</task>

</tasks>

<verification>
1. `python -c "from src.backtesting.analytics import deflated_sharpe; print(deflated_sharpe(2.0, 1, 0.0, 3.0, 252))"` outputs a value > 0.9
2. `python -c "from src.backtesting.analytics import deflated_sharpe; print(deflated_sharpe(2.0, 100, 0.0, 3.0, 252))"` outputs a value < the single-trial value (penalty for multiple testing)
3. `python -c "from src.backtesting.analytics import generate_tearsheet; print(type(generate_tearsheet))"` outputs `<class 'function'>`
4. `python -m pytest tests/test_backtesting_analytics.py -v` -- all pass
5. `python -m pytest tests/test_backtesting.py tests/test_backtesting_v2.py tests/test_backtesting_analytics.py -v` -- all pass (no regressions)
</verification>

<success_criteria>
- deflated_sharpe implements Bailey & Lopez de Prado (2014) DSR and returns probability in [0, 1]
- DSR decreases when n_trials increases (demonstrates multiple testing adjustment)
- compute_sortino, compute_information_ratio, compute_tail_ratio, compute_turnover, compute_rolling_sharpe all work correctly with numpy arrays
- generate_tearsheet produces complete dict with equity_curve, drawdown_chart, monthly_heatmap, rolling_sharpe, trade_analysis, return_distribution sections
- All existing and new tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/14-backtesting-engine-v2-strategy-framework/14-03-SUMMARY.md`
</output>
