---
phase: 16-crossasset-nlp
plan: 03
type: execute
wave: 2
depends_on:
  - 16-02
files_modified:
  - src/nlp/sentiment_analyzer.py
  - src/nlp/nlp_processor.py
  - src/nlp/dictionaries/__init__.py
  - src/nlp/dictionaries/hawk_dove_pt.py
  - src/nlp/dictionaries/hawk_dove_en.py
  - tests/test_sentiment_analyzer.py
  - tests/test_nlp_processor.py
autonomous: true
requirements:
  - NLP-03
  - NLP-04

must_haves:
  truths:
    - "CentralBankSentimentAnalyzer produces hawk/dove scores in [-1, +1] via dictionary-based term matching (PT and EN) with optional LLM refinement"
    - "Analyzer computes change_score vs previous document as categorical + magnitude (hawkish_shift, dovish_shift, neutral, major_hawkish_shift, major_dovish_shift)"
    - "NLPProcessor pipeline runs clean -> score -> extract key phrases -> compare vs previous -> persist, storing results to nlp_documents table"
    - "Key phrases are extracted from scored documents and stored as JSON list"
  artifacts:
    - path: "src/nlp/sentiment_analyzer.py"
      provides: "CentralBankSentimentAnalyzer with dictionary + optional LLM scoring"
      contains: "CentralBankSentimentAnalyzer"
    - path: "src/nlp/nlp_processor.py"
      provides: "NLPProcessor pipeline orchestrator"
      contains: "NLPProcessor"
    - path: "src/nlp/dictionaries/hawk_dove_pt.py"
      provides: "Portuguese hawk/dove term dictionary"
      contains: "HAWK_TERMS_PT"
    - path: "src/nlp/dictionaries/hawk_dove_en.py"
      provides: "English hawk/dove term dictionary"
      contains: "HAWK_TERMS_EN"
    - path: "tests/test_sentiment_analyzer.py"
      provides: "Unit tests for sentiment scoring"
    - path: "tests/test_nlp_processor.py"
      provides: "Unit tests for NLP pipeline"
  key_links:
    - from: "src/nlp/nlp_processor.py"
      to: "src/nlp/sentiment_analyzer.py"
      via: "NLPProcessor calls analyzer.score() in pipeline"
      pattern: "CentralBankSentimentAnalyzer"
    - from: "src/nlp/nlp_processor.py"
      to: "src/core/models/nlp_documents.py"
      via: "persist step updates hawk_score, dove_score, change_score, key_phrases on NlpDocumentRecord"
      pattern: "NlpDocumentRecord"
    - from: "src/nlp/sentiment_analyzer.py"
      to: "src/nlp/dictionaries/hawk_dove_pt.py"
      via: "Analyzer loads PT dictionary for COPOM document scoring"
      pattern: "HAWK_TERMS_PT"
---

<objective>
Build the CentralBankSentimentAnalyzer with hawk/dove scoring via dictionary term matching (Portuguese and English) with optional LLM refinement, and the NLPProcessor pipeline that orchestrates the full clean -> score -> extract -> compare -> persist workflow.

Purpose: Hawk/dove sentiment from central bank communications is a critical signal input for rates, FX, and inflation strategies. The dictionary approach provides deterministic, auditable scoring while the optional LLM layer adds nuance when available.

Output: CentralBankSentimentAnalyzer, NLPProcessor pipeline, PT/EN hawk/dove dictionaries (50-100 terms per language), comprehensive unit tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/16-crossasset-nlp/16-CONTEXT.md
@.planning/phases/16-crossasset-nlp/16-02-SUMMARY.md
@src/core/models/nlp_documents.py
@src/nlp/scrapers/copom_scraper.py
@src/nlp/scrapers/fomc_scraper.py
@src/narrative/generator.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Hawk/dove dictionaries and CentralBankSentimentAnalyzer</name>
  <files>
    src/nlp/dictionaries/__init__.py
    src/nlp/dictionaries/hawk_dove_pt.py
    src/nlp/dictionaries/hawk_dove_en.py
    src/nlp/sentiment_analyzer.py
  </files>
  <action>
**1. Create `src/nlp/dictionaries/__init__.py`** -- package init.

**2. Create `src/nlp/dictionaries/hawk_dove_pt.py`** -- Portuguese hawk/dove terms for COPOM.

Per Claude's discretion: 50-100 terms per language recommended.

HAWK_TERMS_PT: dict[str, float] -- term -> weight (0.0 to 1.0, higher = more hawkish).
~70 terms covering:
- Monetary tightening: "elevacao da selic", "aperto monetario", "juros mais altos", "ciclo de alta", "politica monetaria restritiva"
- Inflation concern: "pressao inflacionaria", "inflacao persistente", "inflacao acima da meta", "reancoragem das expectativas", "nucleo elevado", "inercial"
- Risk aversion: "vigilancia", "cautela", "riscos de alta para inflacao", "deterioracao do cenario"
- BCB-specific: "convergencia para a meta", "horizonte relevante", "expectativas desancoradas"

DOVE_TERMS_PT: dict[str, float] -- same format, ~70 terms:
- Monetary easing: "corte da selic", "flexibilizacao monetaria", "ciclo de queda", "politica monetaria expansionista"
- Inflation comfort: "inflacao controlada", "convergencia para a meta", "nucleo benigno", "expectativas ancoradas"
- Growth concern: "atividade economica fraca", "hiato do produto negativo", "desaceleracao"
- BCB-specific: "espaco para corte", "gradualismo", "parcimonia"

**3. Create `src/nlp/dictionaries/hawk_dove_en.py`** -- English hawk/dove terms for FOMC.

HAWK_TERMS_EN: dict[str, float] -- ~70 terms:
- Tightening: "raise rates", "tightening", "hawkish", "rate hike", "restrictive stance", "further firming"
- Inflation concern: "inflation persistent", "price pressures", "above target", "inflationary risks", "upside risks to inflation"
- Fed-specific: "data dependent", "prepared to raise", "appropriate to increase", "policy firming", "reduce balance sheet"

DOVE_TERMS_EN: dict[str, float] -- ~70 terms:
- Easing: "cut rates", "accommodative", "dovish", "rate cut", "policy easing", "lower rates"
- Inflation comfort: "inflation expectations anchored", "transitory", "inflation declining", "price stability"
- Growth concern: "economic slowdown", "labor market softening", "downside risks", "below potential"
- Fed-specific: "patient", "flexible", "gradual", "supportive", "data suggest"

**4. Create `src/nlp/sentiment_analyzer.py`** (NLP-03):

Per locked decisions:
- Dictionary as primary scoring method
- Optional LLM refinement when API key available
- Change score: categorical + magnitude

CentralBankSentimentAnalyzer class:
- `__init__(self, api_key: str | None = None)`:
  - Load PT and EN dictionaries
  - If api_key provided and anthropic available, set `_llm_available = True`

- `score(self, text: str, language: str = "pt") -> SentimentResult`:
  - Clean text: lowercase, normalize accents, strip punctuation
  - Select dictionary based on language ("pt" or "en")
  - Count hawk term occurrences (weighted by term weight)
  - Count dove term occurrences (weighted by term weight)
  - hawk_score = sum(hawk_weights) / max(1, total_terms_found)
  - dove_score = sum(dove_weights) / max(1, total_terms_found)
  - net_score = hawk_score - dove_score, clipped to [-1, +1]
  - If LLM available: call _refine_with_llm(text, net_score, language) to adjust
  - Return SentimentResult(hawk_score, dove_score, net_score, key_phrases, method)

- `compute_change_score(self, current_score: float, previous_score: float) -> str`:
  - delta = current_score - previous_score
  - Per locked decision -- categorical + magnitude:
    - |delta| > 0.3: "major_hawkish_shift" or "major_dovish_shift"
    - |delta| > 0.1: "hawkish_shift" or "dovish_shift"
    - else: "neutral"

- `extract_key_phrases(self, text: str, language: str, top_n: int = 10) -> list[str]`:
  - Find all dictionary matches in text
  - Return top_n by weight, preserving original phrase context (surrounding 5 words)

- `_refine_with_llm(self, text: str, dict_score: float, language: str) -> float`:
  - Prompt Claude to rate hawk/dove on [-1, +1] given the text
  - Blend: 0.7 * dict_score + 0.3 * llm_score
  - On any LLM error, return dict_score unchanged

SentimentResult dataclass:
- hawk_score: float  # [0, 1]
- dove_score: float  # [0, 1]
- net_score: float  # [-1, +1]
- key_phrases: list[str]
- method: str  # "dictionary" or "dictionary+llm"
  </action>
  <verify>
    Run: `python -c "from src.nlp.dictionaries.hawk_dove_pt import HAWK_TERMS_PT, DOVE_TERMS_PT; print(f'PT: {len(HAWK_TERMS_PT)} hawk, {len(DOVE_TERMS_PT)} dove')"`
    Run: `python -c "from src.nlp.dictionaries.hawk_dove_en import HAWK_TERMS_EN, DOVE_TERMS_EN; print(f'EN: {len(HAWK_TERMS_EN)} hawk, {len(DOVE_TERMS_EN)} dove')"`
    Run: `python -c "from src.nlp.sentiment_analyzer import CentralBankSentimentAnalyzer; a = CentralBankSentimentAnalyzer(); r = a.score('O Copom decidiu elevar a taxa Selic para combater a pressao inflacionaria persistente', 'pt'); print(f'net={r.net_score:.2f}, method={r.method}')"`
    Expected: Positive net_score (hawkish text), method="dictionary".
  </verify>
  <done>
    CentralBankSentimentAnalyzer scores text with dictionary term matching, produces [-1, +1] hawk/dove scores, extracts key phrases, computes categorical change scores. PT dictionary has 50+ hawk and 50+ dove terms. EN dictionary has 50+ hawk and 50+ dove terms.
  </done>
</task>

<task type="auto">
  <name>Task 2: NLPProcessor pipeline and comprehensive tests</name>
  <files>
    src/nlp/nlp_processor.py
    tests/test_sentiment_analyzer.py
    tests/test_nlp_processor.py
  </files>
  <action>
**1. Create `src/nlp/nlp_processor.py`** (NLP-04):

NLPProcessor class -- orchestrates the full NLP pipeline:
- `__init__(self, analyzer: CentralBankSentimentAnalyzer | None = None, session_factory=None)`:
  - If analyzer not provided, create default CentralBankSentimentAnalyzer()
  - session_factory for database persistence (optional, can persist without DB)

- `process_document(self, doc: ScrapedDocument, previous_doc_score: float | None = None) -> ProcessedDocument`:
  Pipeline steps:
  1. **Clean**: normalize text (strip HTML tags, normalize whitespace, handle encoding)
  2. **Score**: call analyzer.score(cleaned_text, language) -> SentimentResult
  3. **Extract**: call analyzer.extract_key_phrases(cleaned_text, language) -> list[str]
  4. **Compare**: if previous_doc_score provided, call analyzer.compute_change_score(current, previous)
  5. Return ProcessedDocument with all fields populated

- `process_batch(self, documents: list[ScrapedDocument], source: str) -> list[ProcessedDocument]`:
  - Sort documents by date ascending
  - Process each document, passing previous document's net_score for change_score computation
  - First document in batch: change_score = "neutral" (no previous)
  - Return list of ProcessedDocument

- `persist_results(self, processed_docs: list[ProcessedDocument], session) -> int`:
  - For each processed doc: UPDATE nlp_documents SET hawk_score, dove_score, change_score, key_phrases WHERE source AND doc_type AND doc_date match
  - Uses session.execute(update(...).where(...).values(...))
  - Returns count of updated records

- `run_pipeline(self, scraped_documents: list[ScrapedDocument], source: str, session=None) -> PipelineResult`:
  - Full pipeline: process_batch -> persist_results (if session provided)
  - Return PipelineResult(documents_processed, documents_persisted, errors)

- `_clean_text(self, raw_text: str) -> str`:
  - Strip HTML tags (regex or html.parser)
  - Normalize Unicode (NFC)
  - Collapse multiple whitespace to single space
  - Strip leading/trailing whitespace

- `_detect_language(self, source: str) -> str`:
  - "copom" -> "pt"
  - "fomc" -> "en"

ProcessedDocument dataclass:
- source, doc_type, doc_date, cleaned_text
- hawk_score, dove_score, net_score, change_score
- key_phrases: list[str]
- method: str

PipelineResult dataclass:
- documents_processed: int
- documents_persisted: int
- errors: list[str]

**2. Create `tests/test_sentiment_analyzer.py`:**
- Test hawk text in PT scores positive (net > 0)
- Test dove text in PT scores negative (net < 0)
- Test hawk text in EN scores positive
- Test dove text in EN scores negative
- Test neutral text scores near zero
- Test change_score: large shift -> "major_hawkish_shift" / "major_dovish_shift"
- Test change_score: small shift -> "hawkish_shift" / "dovish_shift"
- Test change_score: no shift -> "neutral"
- Test extract_key_phrases returns non-empty list for hawk text
- Test score clipped to [-1, +1]
- Test empty text returns near-zero score
- Test mixed hawk/dove text returns intermediate score
- 12-15 tests

**3. Create `tests/test_nlp_processor.py`:**
- Test process_document produces ProcessedDocument with all fields
- Test process_batch computes change_score vs previous
- Test process_batch first document has change_score="neutral"
- Test _clean_text strips HTML tags
- Test _clean_text normalizes whitespace
- Test _detect_language: "copom" -> "pt", "fomc" -> "en"
- Test run_pipeline without session (no persistence, no error)
- Test run_pipeline processes multiple documents in order
- 8-10 tests

All tests must be self-contained (no real HTTP, no real DB). Use ScrapedDocument fixtures with sample text.
  </action>
  <verify>
    Run: `python -m pytest tests/test_sentiment_analyzer.py tests/test_nlp_processor.py -v`
    Expected: All tests pass.
    Run: `python -m pytest tests/ -x --timeout=120`
    Expected: All existing + new tests pass.
  </verify>
  <done>
    NLPProcessor pipeline runs clean -> score -> extract -> compare -> persist. CentralBankSentimentAnalyzer has comprehensive test coverage for both languages. All tests pass with no regressions.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.nlp.sentiment_analyzer import CentralBankSentimentAnalyzer"` -- imports OK
2. `python -c "from src.nlp.nlp_processor import NLPProcessor"` -- imports OK
3. `python -c "from src.nlp.dictionaries.hawk_dove_pt import HAWK_TERMS_PT; print(len(HAWK_TERMS_PT))"` -- 50+ terms
4. `python -c "from src.nlp.dictionaries.hawk_dove_en import HAWK_TERMS_EN; print(len(HAWK_TERMS_EN))"` -- 50+ terms
5. `python -m pytest tests/test_sentiment_analyzer.py tests/test_nlp_processor.py -v` -- all pass
6. `python -m pytest tests/ -x --timeout=120` -- no regressions
</verification>

<success_criteria>
- CentralBankSentimentAnalyzer produces hawk/dove scores [-1, +1] via dictionary with optional LLM (NLP-03)
- NLPProcessor pipeline runs clean -> score -> extract -> compare -> persist (NLP-04)
- Change score is categorical: hawkish_shift, dovish_shift, neutral, major_hawkish_shift, major_dovish_shift
- PT dictionary has 50+ hawk and 50+ dove terms
- EN dictionary has 50+ hawk and 50+ dove terms
- All tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/16-crossasset-nlp/16-03-SUMMARY.md`
</output>
