---
phase: 27-redis-cache-dagster-pms-go-live-verification
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/GOLIVE_CHECKLIST.md
  - docs/OPERATIONAL_RUNBOOK.md
  - docs/DR_PLAYBOOK.md
  - scripts/backup.sh
  - scripts/restore.sh
autonomous: true
requirements:
  - PMS-GL-01
  - PMS-GL-02
  - PMS-GL-03

must_haves:
  truths:
    - "Go-live checklist covers infrastructure, PMS config, data quality, workflow testing, compliance, backups, and monitoring"
    - "Operational runbook describes the manager's daily routine from pre-market through close"
    - "DR playbook covers database failure, Redis failure, incorrect positions, and incorrect MTM scenarios"
    - "Backup script creates timestamped pg_dump of the full database"
    - "Restore script takes a backup file and restores to TimescaleDB"
  artifacts:
    - path: "docs/GOLIVE_CHECKLIST.md"
      provides: "Complete go-live checklist for PMS production deployment"
      contains: "GO-LIVE CHECKLIST"
    - path: "docs/OPERATIONAL_RUNBOOK.md"
      provides: "Daily operational procedures for the portfolio manager"
      contains: "OPERATIONAL RUNBOOK"
    - path: "docs/DR_PLAYBOOK.md"
      provides: "Disaster recovery procedures for 4+ failure scenarios"
      contains: "DISASTER RECOVERY"
    - path: "scripts/backup.sh"
      provides: "Database backup script with timestamped output"
      contains: "pg_dump"
    - path: "scripts/restore.sh"
      provides: "Database restore script from backup file"
      contains: "pg_restore\\|psql"
  key_links:
    - from: "docs/GOLIVE_CHECKLIST.md"
      to: "scripts/backup.sh"
      via: "Checklist references backup script for validation"
      pattern: "scripts/backup.sh"
    - from: "docs/DR_PLAYBOOK.md"
      to: "scripts/restore.sh"
      via: "DR playbook references restore procedure"
      pattern: "scripts/restore.sh"
---

<objective>
Go-live documentation suite: checklist, operational runbook, disaster recovery playbook, and backup/restore scripts.

Purpose: Ensure the system is production-ready with clear operational procedures. The manager needs a tested backup/restore workflow, documented daily routine, and step-by-step recovery procedures for common failure scenarios. This is the operational safety net for the PMS.

Output: 3 documentation files in `docs/` and 2 executable scripts in `scripts/`.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@docker-compose.yml
@Makefile
</context>

<tasks>

<task type="auto">
  <name>Task 1: Go-live checklist and operational runbook</name>
  <files>docs/GOLIVE_CHECKLIST.md, docs/OPERATIONAL_RUNBOOK.md</files>
  <action>
Create `docs/GOLIVE_CHECKLIST.md` following the guide's Etapa 18 structure, adapted to our actual implementation. Use markdown checkboxes. Sections:

**1. Infrastructure Prerequisites**
- [ ] TimescaleDB: connection tested, data up to D-1 available
- [ ] Redis: connected and responding (`redis-cli ping` returns PONG)
- [ ] FastAPI: all endpoints responding (GET /health returns 200)
- [ ] Dagster: PMS pipeline scheduled and tested with manual trigger
- [ ] Docker Compose: `docker compose up -d` starts core services (timescaledb, redis)

**2. PMS Configuration**
- [ ] PMSRiskLimits reviewed and configured in `src/pms/risk_limits_config.py`
- [ ] AUM initial value set in settings (FUND_AUM_BRL)
- [ ] Anthropic API key configured (ANTHROPIC_API_KEY) for LLM narrative (optional -- template fallback exists)
- [ ] Timezone set to America/Sao_Paulo

**3. Data Quality**
- [ ] `python scripts/verify_phase2.py` passes (v3.0 components)
- [ ] `python scripts/verify_phase3.py` passes (v4.0 PMS components)
- [ ] Key series updated: SELIC, DI curve, USDBRL, IPCA
- [ ] At least 252 days of market data for historical VaR
- [ ] 5 agents ran successfully on last business day

**4. PMS Workflow Smoke Test**
- [ ] Open test position: POST /api/v1/pms/book/positions/open
- [ ] Verify DecisionJournal entry created
- [ ] Execute MTM: POST /api/v1/pms/book/mtm
- [ ] Verify P&L calculated correctly
- [ ] Generate Morning Pack: POST /api/v1/pms/morning-pack/generate
- [ ] Verify proposals generated
- [ ] Approve test proposal
- [ ] Reject test proposal with mandatory notes
- [ ] Close test position with realized P&L
- [ ] Verify complete audit trail

**5. Backups**
- [ ] `bash scripts/backup.sh` executes without errors
- [ ] Backup file created in `backups/` directory
- [ ] Restore tested: `bash scripts/restore.sh <backup_file>`
- [ ] DR playbook reviewed

**6. Monitoring**
- [ ] Grafana dashboards loading (4 v3.0 dashboards at port 3002)
- [ ] AlertManager rules configured (10 default rules)
- [ ] Dagster UI accessible at port 3001

Create `docs/OPERATIONAL_RUNBOOK.md` with daily operational procedures:

**06:00 -- Pre-Market**
1. Check Dagster pipeline ran without errors (Dagster UI or email alert)
2. Open PMS -> Morning Pack -> review overnight macro snapshot
3. Review trade proposals (Trade Blotter tab)
4. Check active risk alerts

**08:30 -- Market Open (BRT)**
1. Execute MTM with opening prices (via UI or POST /mtm)
2. Decide on proposals: approve, reject, or modify
3. Execute decided trades manually at broker
4. Record execution prices in system

**Intraday**
1. Update prices if significant market moves (manual MTM)
2. Monitor Risk Monitor page if markets volatile
3. Add notes to Decision Journal if relevant

**17:30 -- Market Close**
1. MTM with closing prices (Dagster EOD pipeline runs automatically at 18:00)
2. Review daily P&L in Position Book
3. Check Risk Monitor post-close
4. Update position theses if needed

**Weekly**
1. Review Performance Attribution (MTD, QTD)
2. Review Decision Journal for pattern analysis
3. Verify backups completed successfully
4. Check disk usage and log rotation
  </action>
  <verify>
Run: `test -f docs/GOLIVE_CHECKLIST.md && test -f docs/OPERATIONAL_RUNBOOK.md && echo "Both docs exist"` -- should print success.
  </verify>
  <done>Go-live checklist with 6 sections and 25+ checkbox items, operational runbook with 4 daily time blocks plus weekly tasks</done>
</task>

<task type="auto">
  <name>Task 2: Backup/restore scripts and DR playbook</name>
  <files>scripts/backup.sh, scripts/restore.sh, docs/DR_PLAYBOOK.md</files>
  <action>
Create `scripts/backup.sh` (executable, bash):
```bash
#!/bin/bash
# Macro Fund PMS -- Database Backup
# Creates timestamped pg_dump of the full TimescaleDB database.
# Usage: bash scripts/backup.sh
set -euo pipefail

DATE=$(date +%Y-%m-%d_%H%M)
BACKUP_DIR="backups/${DATE}"
mkdir -p "$BACKUP_DIR"

echo "Starting backup at $(date)..."

# Full database dump (custom format for pg_restore compatibility)
docker compose exec -T timescaledb pg_dump \
    -U macro_user \
    -d macro_trading \
    -Fc \
    > "${BACKUP_DIR}/macro_trading_${DATE}.pgdump"

echo "Database dump: ${BACKUP_DIR}/macro_trading_${DATE}.pgdump"

# Export PMS tables as CSV for quick inspection
for TABLE in portfolio_positions trade_proposals decision_journal daily_briefings position_pnl_history; do
    docker compose exec -T timescaledb psql \
        -U macro_user -d macro_trading \
        -c "\\COPY ${TABLE} TO STDOUT CSV HEADER" \
        > "${BACKUP_DIR}/${TABLE}_${DATE}.csv" 2>/dev/null || true
done

echo "CSV exports: ${BACKUP_DIR}/*.csv"

# Calculate backup size
SIZE=$(du -sh "$BACKUP_DIR" | cut -f1)
echo ""
echo "Backup complete: ${BACKUP_DIR} (${SIZE})"
echo "Finished at $(date)"
```

Create `scripts/restore.sh` (executable, bash):
```bash
#!/bin/bash
# Macro Fund PMS -- Database Restore
# Restores from a pg_dump backup file.
# Usage: bash scripts/restore.sh <backup_file.pgdump>
set -euo pipefail

BACKUP_FILE="${1:?Usage: bash scripts/restore.sh <backup_file.pgdump>}"

if [ ! -f "$BACKUP_FILE" ]; then
    echo "ERROR: Backup file not found: $BACKUP_FILE"
    exit 1
fi

echo "WARNING: This will overwrite the current database!"
echo "Backup file: $BACKUP_FILE"
echo ""
read -p "Continue? (yes/no): " CONFIRM
if [ "$CONFIRM" != "yes" ]; then
    echo "Aborted."
    exit 0
fi

echo "Stopping application services..."
docker compose stop dagster-webserver 2>/dev/null || true

echo "Restoring database..."
# Drop and recreate (clean restore)
docker compose exec -T timescaledb psql -U macro_user -d postgres \
    -c "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname='macro_trading' AND pid <> pg_backend_pid();" 2>/dev/null || true
docker compose exec -T timescaledb psql -U macro_user -d postgres \
    -c "DROP DATABASE IF EXISTS macro_trading;" 2>/dev/null || true
docker compose exec -T timescaledb psql -U macro_user -d postgres \
    -c "CREATE DATABASE macro_trading OWNER macro_user;"

# Restore from dump
cat "$BACKUP_FILE" | docker compose exec -T timescaledb pg_restore \
    -U macro_user \
    -d macro_trading \
    --no-owner \
    --no-acl \
    --clean \
    --if-exists 2>/dev/null || true

echo "Running verification..."
python scripts/verify_phase3.py || echo "WARNING: Some verification checks failed"

echo ""
echo "Restore complete. Restart services with: docker compose up -d"
```

Make both scripts executable via `chmod +x`.

Create `docs/DR_PLAYBOOK.md` with 4+ recovery scenarios:

**Scenario 1: Database Unavailable**
- Symptoms: API returns 500, dashboard blank
- Steps: check docker status, restart timescaledb, wait 30s, verify /health
- If corrupted: restore from backup using scripts/restore.sh

**Scenario 2: Redis Unavailable**
- Symptoms: API slower than usual, no "cached" header in responses
- Steps: `docker compose up redis -d` (cache is stateless -- no data loss)
- Verify: GET /health returns 200, cache rebuilds on next request

**Scenario 3: Incorrect Position Recorded**
- Steps: Do NOT delete (immutability). Close position at entry price (net zero P&L). Add explanatory note in Decision Journal. Open correct position.

**Scenario 4: Incorrect MTM (Wrong Price)**
- Steps: POST /api/v1/pms/book/mtm with manual price override. Record correction in Journal.

**Scenario 5: Dagster Pipeline Failure**
- Symptoms: Morning Pack not generated, stale data
- Steps: Check Dagster UI for error details. Manual trigger via `make dagster-run-all` or individual API calls.
- Fallback: Generate morning pack manually via POST /api/v1/pms/morning-pack/generate

**Restore Procedure** (cross-referenced from all scenarios):
```
1. docker compose stop (except timescaledb, redis)
2. bash scripts/restore.sh <backup_file>
3. python scripts/verify_phase3.py
4. docker compose up -d
```
  </action>
  <verify>
Run: `test -x scripts/backup.sh && test -x scripts/restore.sh && test -f docs/DR_PLAYBOOK.md && echo "All DR artifacts exist and scripts are executable"` -- should print success.
  </verify>
  <done>backup.sh creates timestamped pg_dump + CSV exports, restore.sh restores with confirmation prompt, DR playbook covers 5 failure scenarios with step-by-step recovery</done>
</task>

</tasks>

<verification>
1. `test -f docs/GOLIVE_CHECKLIST.md` -- exists
2. `test -f docs/OPERATIONAL_RUNBOOK.md` -- exists
3. `test -f docs/DR_PLAYBOOK.md` -- exists
4. `test -x scripts/backup.sh` -- executable
5. `test -x scripts/restore.sh` -- executable
6. Go-live checklist has 25+ checkbox items across 6 sections
7. DR playbook covers 5+ scenarios including full restore procedure
</verification>

<success_criteria>
- Go-live checklist comprehensive (infrastructure, config, data, workflow test, backups, monitoring)
- Operational runbook covers daily routine from 06:00 through 17:30 plus weekly tasks
- DR playbook covers database, Redis, position errors, MTM errors, and pipeline failures
- Backup script creates timestamped dumps; restore script restores with confirmation
</success_criteria>

<output>
After completion, create `.planning/phases/27-redis-cache-dagster-pms-go-live-verification/27-03-SUMMARY.md`
</output>
